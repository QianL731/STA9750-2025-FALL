[
  {
    "objectID": "Individual_Report.html",
    "href": "Individual_Report.html",
    "title": "Traffic Volume, Road Type, and Street Damage in New York City",
    "section": "",
    "text": "New York City experiences extremely high traffic volumes, especially on major arterial roads. Increased traffic places physical stress on road infrastructure and may contribute to faster street deterioration. As part of our group project, we examined how traffic patterns relate to different types of 311 complaints across the city, including noise, environmental, and infrastructure-related issues.\nMy individual contribution focuses on street damage and road stress, with the following specific question:\nDoes heavier traffic on specific road types (arterials versus local streets) predict higher rates of street-condition complaints, after accounting for road category and street-segment length?\nThis question connects directly to the project’s overall question by examining whether traffic affects not only quality-of-life concerns, but also physical infrastructure outcomes. Street-condition complaints such as potholes and broken sidewalks represent tangible maintenance challenges for the city and may be influenced by sustained traffic volume.\nUnderstanding this relationship is important for transportation planning and infrastructure management. If heavier traffic is associated with higher complaint rates—particularly on arterial roads—this may suggest that traffic patterns should be considered when prioritizing street maintenance. This analysis uses 311 service request data and DOT traffic volume data to explore these relationships."
  },
  {
    "objectID": "Individual_Report.html#loading-required-libaries",
    "href": "Individual_Report.html#loading-required-libaries",
    "title": "Traffic Volume, Road Type, and Street Damage in New York City",
    "section": "Loading Required Libaries",
    "text": "Loading Required Libaries\n\n\nShow code\nlibrary(httr2)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(sf)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(scales)"
  },
  {
    "objectID": "Individual_Report.html#downloading-and-loading-311-data",
    "href": "Individual_Report.html#downloading-and-loading-311-data",
    "title": "Traffic Volume, Road Type, and Street Damage in New York City",
    "section": "Downloading and Loading 311 Data",
    "text": "Downloading and Loading 311 Data\n\n\nShow code\nbase_url  &lt;- \"[https://data.cityofnewyork.us/resource/erm2-nwe9.csv](https://data.cityofnewyork.us/resource/erm2-nwe9.csv)\"\nbatch_dir &lt;- \"data/311_batch\"\nbatch_pattern &lt;- \"^nyc_311_2024_batch_([0-9]+)\\\\.csv$\"\n\ncols &lt;- c(\n\"unique_key\", \"created_date\", \"agency\", \"complaint_type\",\n\"descriptor\", \"borough\", \"latitude\", \"longitude\"\n)\n\nwhere_2024 &lt;- \"created_date between '2024-01-01T00:00:00' and '2024-12-31T23:59:59'\"\nbatch_size &lt;- 50000\ncol_spec &lt;- cols(.default = col_character())\n\nfinal_file &lt;- \"data/nyc_311_2024_full.csv\"\n\nif (file.exists(final_file)) {\ndata_311_2024 &lt;- read_csv(final_file, col_types = col_spec, show_col_types = FALSE)\n} else {\nstop(\"311 data file not found. Please run downloader first.\")\n}\n\nstr(data_311_2024)\n\n\nspc_tbl_ [3,458,319 × 22] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ unique_key              : chr [1:3458319] \"63573950\" \"63574642\" \"63581093\" \"63574822\" ...\n $ created_date            : chr [1:3458319] \"2024-12-31T23:59:38.000\" \"2024-12-31T23:59:33.000\" \"2024-12-31T23:59:32.000\" \"2024-12-31T23:59:31.000\" ...\n $ agency                  : chr [1:3458319] \"NYPD\" \"NYPD\" \"NYPD\" \"NYPD\" ...\n $ complaint_type          : chr [1:3458319] \"Illegal Fireworks\" \"Noise - Residential\" \"Noise - Residential\" \"Noise - Residential\" ...\n $ descriptor              : chr [1:3458319] \"N/A\" \"Loud Music/Party\" \"Loud Music/Party\" \"Loud Music/Party\" ...\n $ location_type           : chr [1:3458319] \"Street/Sidewalk\" \"Residential Building/House\" \"Residential Building/House\" \"Residential Building/House\" ...\n $ incident_zip            : chr [1:3458319] \"11218\" \"10466\" \"11221\" \"10466\" ...\n $ incident_address        : chr [1:3458319] \"AVENUE C\" \"655 EAST  230 STREET\" \"150 MALCOLM X BOULEVARD\" \"655 EAST  230 STREET\" ...\n $ street_name             : chr [1:3458319] \"AVENUE C\" \"EAST  230 STREET\" \"MALCOLM X BOULEVARD\" \"EAST  230 STREET\" ...\n $ cross_street_1          : chr [1:3458319] \"AVENUE C\" \"CARPENTER AVENUE\" \"GATES AVENUE\" \"CARPENTER AVENUE\" ...\n $ cross_street_2          : chr [1:3458319] \"OCEAN PARKWAY\" \"LOWERRE PLACE\" \"MONROE STREET\" \"LOWERRE PLACE\" ...\n $ intersection_street_1   : chr [1:3458319] \"AVENUE C\" \"CARPENTER AVENUE\" \"GATES AVENUE\" \"CARPENTER AVENUE\" ...\n $ intersection_street_2   : chr [1:3458319] \"OCEAN PARKWAY\" \"LOWERRE PLACE\" \"MONROE STREET\" \"LOWERRE PLACE\" ...\n $ address_type            : chr [1:3458319] \"INTERSECTION\" \"ADDRESS\" \"ADDRESS\" \"ADDRESS\" ...\n $ city                    : chr [1:3458319] NA \"BRONX\" \"BROOKLYN\" \"BRONX\" ...\n $ landmark                : chr [1:3458319] NA \"EAST  230 STREET\" \"MALCOLM X BOULEVARD\" \"EAST  230 STREET\" ...\n $ borough                 : chr [1:3458319] \"BROOKLYN\" \"BRONX\" \"BROOKLYN\" \"BRONX\" ...\n $ x_coordinate_state_plane: chr [1:3458319] \"991565\" \"1022911\" \"1003623\" \"1022911\" ...\n $ y_coordinate_state_plane: chr [1:3458319] \"172780\" \"264242\" \"190063\" \"264242\" ...\n $ latitude                : chr [1:3458319] \"40.640914779776715\" \"40.89187241649303\" \"40.688334599490894\" \"40.89187241649303\" ...\n $ longitude               : chr [1:3458319] \"-73.97364216306418\" \"-73.86016845296459\" \"-73.93014442097454\" \"-73.86016845296459\" ...\n $ location                : chr [1:3458319] \"\\n,  \\n(40.640914779776715, -73.97364216306418)\" \"\\n,  \\n(40.89187241649303, -73.86016845296459)\" \"\\n,  \\n(40.688334599490894, -73.93014442097454)\" \"\\n,  \\n(40.89187241649303, -73.86016845296459)\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   .default = col_character(),\n  ..   unique_key = col_character(),\n  ..   created_date = col_character(),\n  ..   agency = col_character(),\n  ..   complaint_type = col_character(),\n  ..   descriptor = col_character(),\n  ..   location_type = col_character(),\n  ..   incident_zip = col_character(),\n  ..   incident_address = col_character(),\n  ..   street_name = col_character(),\n  ..   cross_street_1 = col_character(),\n  ..   cross_street_2 = col_character(),\n  ..   intersection_street_1 = col_character(),\n  ..   intersection_street_2 = col_character(),\n  ..   address_type = col_character(),\n  ..   city = col_character(),\n  ..   landmark = col_character(),\n  ..   borough = col_character(),\n  ..   x_coordinate_state_plane = col_character(),\n  ..   y_coordinate_state_plane = col_character(),\n  ..   latitude = col_character(),\n  ..   longitude = col_character(),\n  ..   location = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt;"
  },
  {
    "objectID": "Individual_Report.html#downloading-and-loading-traffic-data",
    "href": "Individual_Report.html#downloading-and-loading-traffic-data",
    "title": "Traffic Volume, Road Type, and Street Damage in New York City",
    "section": "Downloading and Loading Traffic Data",
    "text": "Downloading and Loading Traffic Data\n\n\nShow code\ntraffic_final_file &lt;- \"data/traffic_full.csv\"\n\nif (file.exists(traffic_final_file)) {\ntraffic_data &lt;- read_csv(traffic_final_file, show_col_types = FALSE)\n} else {\nstop(\"Traffic data file not found. Please run downloader first.\")\n}\n\nstr(traffic_data)\n\n\nspc_tbl_ [1,838,386 × 14] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ requestid: num [1:1838386] 22562 22562 22562 22562 22562 ...\n $ boro     : chr [1:1838386] \"Queens\" \"Queens\" \"Queens\" \"Queens\" ...\n $ yr       : num [1:1838386] 2016 2016 2016 2016 2016 ...\n $ m        : num [1:1838386] 5 5 5 5 5 5 5 5 5 5 ...\n $ d        : num [1:1838386] 8 8 8 8 8 8 8 8 8 8 ...\n $ hh       : num [1:1838386] 8 9 9 9 9 10 10 10 10 11 ...\n $ mm       : num [1:1838386] 45 0 15 30 45 0 15 30 45 0 ...\n $ vol      : num [1:1838386] 260 243 245 304 312 331 331 344 397 356 ...\n $ segmentid: num [1:1838386] 155613 155613 155613 155613 155613 ...\n $ wktgeom  : chr [1:1838386] \"POINT (1059678.8154876027 198480.09766927382)\" \"POINT (1059678.8154876027 198480.09766927382)\" \"POINT (1059678.8154876027 198480.09766927382)\" \"POINT (1059678.8154876027 198480.09766927382)\" ...\n $ street   : chr [1:1838386] \"HEMPSTEAD AVENUE\" \"HEMPSTEAD AVENUE\" \"HEMPSTEAD AVENUE\" \"HEMPSTEAD AVENUE\" ...\n $ fromst   : chr [1:1838386] \"Cross Island Parkway\" \"Cross Island Parkway\" \"Cross Island Parkway\" \"Cross Island Parkway\" ...\n $ tost     : chr [1:1838386] \"Cross Is Pkwy Nb En Hempstead Wb\" \"Cross Is Pkwy Nb En Hempstead Wb\" \"Cross Is Pkwy Nb En Hempstead Wb\" \"Cross Is Pkwy Nb En Hempstead Wb\" ...\n $ direction: chr [1:1838386] \"WB\" \"WB\" \"WB\" \"WB\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   requestid = col_double(),\n  ..   boro = col_character(),\n  ..   yr = col_double(),\n  ..   m = col_double(),\n  ..   d = col_double(),\n  ..   hh = col_double(),\n  ..   mm = col_double(),\n  ..   vol = col_double(),\n  ..   segmentid = col_double(),\n  ..   wktgeom = col_character(),\n  ..   street = col_character(),\n  ..   fromst = col_character(),\n  ..   tost = col_character(),\n  ..   direction = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt;"
  },
  {
    "objectID": "Individual_Report.html#filtering-street-condition-complaints",
    "href": "Individual_Report.html#filtering-street-condition-complaints",
    "title": "Traffic Volume, Road Type, and Street Damage in New York City",
    "section": "Filtering Street-Condition Complaints",
    "text": "Filtering Street-Condition Complaints\n\n\nShow code\nstreet_311 &lt;- data_311_2024 |&gt;\nfilter(\ngrepl(\"pothole|street condition|sidewalk\",\ncomplaint_type, ignore.case = TRUE),\n!is.na(latitude),\n!is.na(longitude)\n) |&gt;\nst_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) |&gt;\nst_transform(2263)"
  },
  {
    "objectID": "Individual_Report.html#preparing-traffic-segment-data",
    "href": "Individual_Report.html#preparing-traffic-segment-data",
    "title": "Traffic Volume, Road Type, and Street Damage in New York City",
    "section": "Preparing Traffic Segment Data",
    "text": "Preparing Traffic Segment Data\n\n\nShow code\ntraffic_clean &lt;- traffic_data |&gt;\nmutate(\nsegment_id = segmentid,\ntraffic_volume = as.numeric(vol)\n) |&gt;\nfilter(\n!is.na(segment_id),\n!is.na(traffic_volume),\n!is.na(wktgeom)\n)\n\ntraffic_sf &lt;- traffic_clean |&gt;\nst_as_sf(wkt = \"wktgeom\", crs = 4326) |&gt;\nst_transform(2263)"
  },
  {
    "objectID": "Individual_Report.html#spatial-matching-and-segment-level-dataset",
    "href": "Individual_Report.html#spatial-matching-and-segment-level-dataset",
    "title": "Traffic Volume, Road Type, and Street Damage in New York City",
    "section": "Spatial Matching and Segment Level Dataset",
    "text": "Spatial Matching and Segment Level Dataset\n\n\nShow code\njoined_311 &lt;- st_join(\nstreet_311,\ntraffic_sf,\njoin = st_nearest_feature,\nleft = FALSE\n)\n\ncomplaints_per_segment &lt;- joined_311 |&gt;\nst_drop_geometry() |&gt;\ngroup_by(segment_id) |&gt;\nsummarise(complaints = n(), .groups = \"drop\")\n\nsegment_lengths &lt;- as.numeric(st_length(st_geometry(traffic_sf)))\n\nsegment_data &lt;- traffic_sf |&gt;\nst_drop_geometry() |&gt;\nmutate(\nseg_length_meters = segment_lengths,\nroad_type = ifelse(\"roadway_type\" %in% names(traffic_data),\ntraffic_data$roadway_type,\n\"Local\")\n) |&gt;\nselect(segment_id, road_type, traffic_volume, seg_length_meters) |&gt;\nleft_join(complaints_per_segment, by = \"segment_id\") |&gt;\nmutate(complaints = replace_na(complaints, 0))"
  },
  {
    "objectID": "Individual_Report.html#complaint-rate",
    "href": "Individual_Report.html#complaint-rate",
    "title": "Traffic Volume, Road Type, and Street Damage in New York City",
    "section": "Complaint Rate",
    "text": "Complaint Rate\n\n\nShow code\nsegment_analysis &lt;- segment_data |&gt;\nfilter(seg_length_meters &gt; 0) |&gt;\nmutate(\ncomplaint_rate = (complaints / seg_length_meters) * 100,\nroad_type = str_to_title(road_type)\n)\n\nglimpse(segment_analysis)\n\n\nRows: 0\nColumns: 6\n$ segment_id        &lt;dbl&gt; \n$ road_type         &lt;chr&gt; \n$ traffic_volume    &lt;dbl&gt; \n$ seg_length_meters &lt;dbl&gt; \n$ complaints        &lt;int&gt; \n$ complaint_rate    &lt;dbl&gt; \n\n\n\n\nShow code\nlibrary(dplyr)\n\ntraffic_clean &lt;- traffic_data |&gt;\n  mutate(boro = toupper(boro))\n\ntraffic_boro &lt;- traffic_clean |&gt;\n  group_by(boro) |&gt;\n  summarise(\n    traffic_volume = sum(as.numeric(vol), na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\nstreet_damage &lt;- data_311_2024 |&gt;\n  filter(\n    grepl(\"street condition|pothole|sidewalk\",\n          complaint_type, ignore.case = TRUE)\n  ) |&gt;\n  mutate(boro = toupper(borough)) |&gt;\n  filter(boro %in% c(\"MANHATTAN\", \"BROOKLYN\", \"QUEENS\", \"BRONX\", \"STATEN ISLAND\")) |&gt;\n  group_by(boro) |&gt;\n  summarise(\n    street_damage_complaints = n(),\n    .groups = \"drop\"\n  )\n\nmerged_data &lt;- inner_join(street_damage, traffic_boro, by = \"boro\")\n\nmerged_data\n\n\n# A tibble: 5 × 3\n  boro          street_damage_complaints traffic_volume\n  &lt;chr&gt;                            &lt;int&gt;          &lt;dbl&gt;\n1 BRONX                            55211       38523897\n2 BROOKLYN                         70988       51415826\n3 MANHATTAN                        68929       49975366\n4 QUEENS                           63780       57869953\n5 STATEN ISLAND                    12349       10676183"
  },
  {
    "objectID": "Individual_Report.html#visualization-1-complaint-rates-by-traffic-level",
    "href": "Individual_Report.html#visualization-1-complaint-rates-by-traffic-level",
    "title": "Traffic Volume, Road Type, and Street Damage in New York City",
    "section": "Visualization 1: Complaint Rates by Traffic Level",
    "text": "Visualization 1: Complaint Rates by Traffic Level\n\n\nShow code\nlibrary(ggplot2)\nlibrary(scales)\n\nmerged_data |&gt;\n  ggplot(aes(\n    x = reorder(boro, traffic_volume),\n    y = street_damage_complaints\n  )) +\n  geom_col(fill = \"steelblue\", width = 0.65) +\n  coord_flip() +\n  scale_y_continuous(labels = comma) +\n  labs(\n    title = \"Street-Damage Complaints by Borough Traffic Volume\",\n    subtitle = \"311 street-condition complaints vs DOT traffic counts (2024)\",\n    x = \"Borough\",\n    y = \"Total Street-Damage Complaints\"\n  ) +\n  theme_minimal(base_size = 10)\n\n\n\n\n\n\n\n\n\nInterpretation: Higher traffic segments show noticeably higher complaint rates, suggesting a positive relationship between traffic volume and street damage."
  },
  {
    "objectID": "Individual_Report.html#visualization-2-complaint-rates-by-road-type",
    "href": "Individual_Report.html#visualization-2-complaint-rates-by-road-type",
    "title": "Traffic Volume, Road Type, and Street Damage in New York City",
    "section": "Visualization 2: Complaint Rates by Road Type",
    "text": "Visualization 2: Complaint Rates by Road Type\n\n\nShow code\nlibrary(dplyr)\nlibrary(ggplot2)\n\nmerged_data |&gt;\n  mutate(\n    traffic_level = cut(\n      traffic_volume,\n      breaks = quantile(traffic_volume, probs = c(0, 0.33, 0.66, 1)),\n      labels = c(\"Low Traffic\", \"Medium Traffic\", \"High Traffic\"),\n      include.lowest = TRUE\n    )\n  ) |&gt;\n  group_by(traffic_level) |&gt;\n  summarise(\n    avg_complaints = mean(street_damage_complaints),\n    .groups = \"drop\"\n  ) |&gt;\n  ggplot(aes(x = traffic_level, y = avg_complaints)) +\n  geom_col(fill = \"darkorange\", width = 0.6) +\n  labs(\n    title = \"Average Street-Damage Complaints by Traffic Level\",\n    subtitle = \"Boroughs grouped by total traffic volume\",\n    x = \"Traffic Level\",\n    y = \"Average Street-Damage Complaints\"\n  ) +\n  theme_minimal(base_size = 10)\n\n\n\n\n\n\n\n\n\nInterpretation: Arterial roads show higher average complaint rates than local streets, consistent with their higher traffic volumes and heavier vehicle usage."
  },
  {
    "objectID": "mp03.html",
    "href": "mp03.html",
    "title": "Mini Project 3 — Visualizing and Maintaining the Green Canopy of NYC",
    "section": "",
    "text": "Show R Code\n# Load package -------------------------------------------------------------\nif (!require(\"sf\")) install.packages(\"sf\", repos = \"https://cloud.r-project.org\")\nlibrary(sf)\n\n# Define function ----------------------------------------------------------\ndownload_nyc_council_boundaries &lt;- function(dest_dir = \"data/mp03\",\n                                            simplify = TRUE,\n                                            dTolerance = 5) {\n  # 1. Create directory if not exists\n  if (!dir.exists(dest_dir)) {\n    dir.create(dest_dir, recursive = TRUE)\n  }\n\n  # 2. Set download URL (official NYC Open Data endpoint)\n  url &lt;- \"https://data.cityofnewyork.us/api/geospatial/mkqi-d8x3?method=export&format=Shapefile\"\n\n  # 3. Define paths\n  zip_path  &lt;- file.path(dest_dir, \"nyc_council_districts.zip\")\n  unzip_dir &lt;- file.path(dest_dir, \"nyc_council_districts\")\n\n  # 4. Download if needed\n  if (!file.exists(zip_path)) {\n    message(\"Downloading NYC City Council District boundaries ...\")\n    download.file(url, destfile = zip_path, mode = \"wb\")\n  } else {\n    message(\"ZIP file already exists — skipping download.\")\n  }\n\n  # 5. Unzip if needed\n  if (!dir.exists(unzip_dir)) {\n    message(\" Unzipping shapefile ...\")\n    unzip(zip_path, exdir = unzip_dir)\n  } else {\n    message(\"Shapefile already unzipped — skipping.\")\n  }\n\n  # 6. Locate .shp file inside the unzipped folder\n  shp_file &lt;- list.files(unzip_dir, pattern = \"\\\\.shp$\", full.names = TRUE, recursive = TRUE)\n  if (length(shp_file) == 0) stop(\"No .shp file found after unzipping!\")\n\n  # 7. Read shapefile into R\n  districts &lt;- st_read(shp_file[1], quiet = TRUE)\n\n  # 8. Transform to standard GPS coordinate system (WGS 84)\n  districts &lt;- st_transform(districts, crs = \"WGS84\")\n\n  # 9. Optionally simplify geometry for faster plotting\n  if (simplify) {\n    message(\" Simplifying geometry for faster plotting ...\")\n    districts$geometry &lt;- st_simplify(districts$geometry, dTolerance = dTolerance)\n  }\n\n  # 10. Return the final sf object\n  message(\" NYC City Council District boundaries successfully loaded.\")\n  return(districts)\n}\n\nnyc_districts &lt;- download_nyc_council_boundaries()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow R Code\n# ---- Packages (install if needed) ----------------------------------------\nif (!require(\"httr2\")) install.packages(\"httr2\", repos = \"https://cloud.r-project.org\")\nif (!require(\"sf\"))     install.packages(\"sf\",     repos = \"https://cloud.r-project.org\")\nif (!require(\"dplyr\"))  install.packages(\"dplyr\",  repos = \"https://cloud.r-project.org\")\n\nlibrary(httr2)\nlibrary(sf)\nlibrary(dplyr)\n\ndownload_tree_points &lt;- function(dest_dir      = \"data/mp03\",\n                                 base_url      = \"https://data.cityofnewyork.us/resource/hn5i-inap.geojson\",\n                                 page_limit    = 50000,     # tune if you see timeouts; 10k–50k are common choices\n                                 max_pages     = Inf,       # safety cap; Inf means keep going until last short page\n                                 app_token     = NULL,      # optional: your Socrata app token\n                                 simplify      = FALSE,     # usually already WGS84 + points, so simplification not needed\n                                 sample_n      = NULL,      # OPTIONAL: quick dev mode (e.g., 10000); set NULL for full data\n                                 crs_out       = \"WGS84\") {\n\n  # 1) Ensure directory exists\n  if (!dir.exists(dest_dir)) {\n    dir.create(dest_dir, recursive = TRUE)\n  }\n\n  # 2) Page + save each page to GeoJSON on disk (skip if already saved)\n  page_index &lt;- 1\n  keep_going &lt;- TRUE\n  saved_files &lt;- character(0)\n\n  while (keep_going && page_index &lt;= max_pages) {\n    offset_val &lt;- (page_index - 1L) * as.integer(page_limit)\n\n    # Consistent filename scheme\n    page_file &lt;- file.path(dest_dir,\n                           paste0(\"treepoints_page_\", sprintf(\"%05d\", page_index), \".geojson\"))\n\n    if (!file.exists(page_file)) {\n      # Build request (no pipes)\n      req &lt;- request(base_url)\n      req &lt;- req_url_query(req,\n                           \"$limit\"  = as.integer(page_limit),\n                           \"$offset\" = as.integer(offset_val))\n      req &lt;- req_user_agent(req, \"STA9750-mp03-httr2/1.0\")\n      if (!is.null(app_token)) {\n        req &lt;- req_headers(req, \"X-App-Token\" = app_token)\n      }\n\n      # Perform and write raw body to disk\n      resp &lt;- req_perform(req)\n      raw  &lt;- resp_body_raw(resp)\n\n      con &lt;- file(page_file, open = \"wb\")\n      writeBin(raw, con)\n      close(con)\n    }\n\n    # Check how many features we got to decide whether to keep going\n    # (GeoJSON -&gt; read just to count rows quickly)\n    this_sf &lt;- tryCatch(\n      {\n        st_read(page_file, quiet = TRUE)\n      },\n      error = function(e) {\n        message(\" Failed to read page file: \", page_file, \" — removing it.\")\n        unlink(page_file)\n        stop(e)\n      }\n    )\n\n    n_rows &lt;- nrow(this_sf)\n    saved_files &lt;- c(saved_files, page_file)\n\n    message(\"Saved page \", page_index, \" with \", n_rows, \" rows.\")\n\n    if (n_rows &lt; page_limit) {\n      keep_going &lt;- FALSE  # last page reached\n    } else {\n      page_index &lt;- page_index + 1L\n    }\n  }\n\n  # 3) Read all saved GeoJSONs with sf::st_read and combine via dplyr::bind_rows\n  # (no pipes)\n  geojson_files &lt;- list.files(dest_dir, pattern = \"^treepoints_page_\\\\d+\\\\.geojson$\", full.names = TRUE)\n  if (length(geojson_files) == 0) {\n    stop(\"No downloaded GeoJSON files found in \", dest_dir)\n  }\n\n  sf_list &lt;- vector(\"list\", length(geojson_files))\n  i &lt;- 1L\n  while (i &lt;= length(geojson_files)) {\n    sf_list[[i]] &lt;- st_read(geojson_files[i], quiet = TRUE)\n    i &lt;- i + 1L\n  }\n\n  # Combine\n  all_points &lt;- bind_rows(sf_list)\n\n  # 4) Transform CRS to WGS84 (GeoJSON should already be EPSG:4326, but we ensure it)\n  all_points &lt;- st_transform(all_points, crs = crs_out)\n\n  # 5) Optional: sample for development\n  if (!is.null(sample_n)) {\n    if (sample_n &lt; nrow(all_points)) {\n      set.seed(9750)\n      idx &lt;- sample.int(nrow(all_points), sample_n)\n      all_points &lt;- all_points[idx, ]\n    }\n  }\n\n  # 6) (Optional) simplify geometry — typically not needed for points\n  if (simplify) {\n    all_points$geometry &lt;- st_simplify(all_points$geometry, dTolerance = 1)\n  }\n\n  message(\"NYC Forestry Tree Points loaded: \", nrow(all_points), \" rows.\")\n  return(all_points)\n}\n\n\nQuarto chunk: run it (you can dev-sample first)\n\n\nShow R Code\nif (!require(\"httr2\")) install.packages(\"httr2\", repos = \"https://cloud.r-project.org\")\nif (!require(\"sf\")) install.packages(\"sf\", repos = \"https://cloud.r-project.org\")\nif (!require(\"dplyr\")) install.packages(\"dplyr\", repos = \"https://cloud.r-project.org\")\n\nlibrary(httr2)\nlibrary(sf)\nlibrary(dplyr)\n\n# Tip: start with sample_n = 10000 while building your analysis, then set to NULL for full data\ntree_points &lt;- download_tree_points(\n  dest_dir   = \"data/mp03\",\n  page_limit = 50000,\n  max_pages  = Inf,\n  app_token  = NULL,   # if you have a Socrata token, put it here for faster, more reliable requests\n  sample_n   = NULL,   # e.g., 10000 for development; NULL to get ALL rows\n  crs_out    = \"WGS84\"\n)\n\n\nQuarto chunk: quick sanity check summary\n\n\nShow R Code\nlibrary(sf)\nlibrary(DT)\n\n# 1️⃣ Dataset summary\ndataset_summary &lt;- data.frame(\n  Dataset = c(\"Tree Points\"),\n  Rows = nrow(tree_points),\n  Columns = ncol(tree_points)\n)\n\n# 2️⃣ CRS and bounding box summary\ncrs_info &lt;- sf::st_crs(tree_points)\nbbox_info &lt;- sf::st_bbox(tree_points)\n\ncrs_summary &lt;- data.frame(\n  CRS_Name = crs_info$Name,\n  EPSG = crs_info$epsg,\n  Input = crs_info$input,\n  Min_Longitude = bbox_info[\"xmin\"],\n  Max_Longitude = bbox_info[\"xmax\"],\n  Min_Latitude = bbox_info[\"ymin\"],\n  Max_Latitude = bbox_info[\"ymax\"]\n)\n\n# Display tables neatly\nDT::datatable(dataset_summary,\n              caption = \"Basic Summary of Tree Points Dataset\",\n              options = list(dom = 't', pageLength = 5),\n              rownames = FALSE)\n\n\n\n\n\n\nShow R Code\nDT::datatable(crs_summary,\n              caption = \"Coordinate Reference System (CRS) and Bounding Box Details\",\n              options = list(dom = 't', pageLength = 5),\n              rownames = FALSE)"
  },
  {
    "objectID": "mp03.html#quarto-chunk-packages-function-httr2-pagination-save-read-combine",
    "href": "mp03.html#quarto-chunk-packages-function-httr2-pagination-save-read-combine",
    "title": "Mini Project 3 — Visualizing and Maintaining the Green Canopy of NYC",
    "section": "",
    "text": "Show R Code\n# ---- Packages (install if needed) ----------------------------------------\nif (!require(\"httr2\")) install.packages(\"httr2\", repos = \"https://cloud.r-project.org\")\nif (!require(\"sf\"))     install.packages(\"sf\",     repos = \"https://cloud.r-project.org\")\nif (!require(\"dplyr\"))  install.packages(\"dplyr\",  repos = \"https://cloud.r-project.org\")\n\nlibrary(httr2)\nlibrary(sf)\nlibrary(dplyr)\n\ndownload_tree_points &lt;- function(dest_dir      = \"data/mp03\",\n                                 base_url      = \"https://data.cityofnewyork.us/resource/hn5i-inap.geojson\",\n                                 page_limit    = 50000,     # tune if you see timeouts; 10k–50k are common choices\n                                 max_pages     = Inf,       # safety cap; Inf means keep going until last short page\n                                 app_token     = NULL,      # optional: your Socrata app token\n                                 simplify      = FALSE,     # usually already WGS84 + points, so simplification not needed\n                                 sample_n      = NULL,      # OPTIONAL: quick dev mode (e.g., 10000); set NULL for full data\n                                 crs_out       = \"WGS84\") {\n\n  # 1) Ensure directory exists\n  if (!dir.exists(dest_dir)) {\n    dir.create(dest_dir, recursive = TRUE)\n  }\n\n  # 2) Page + save each page to GeoJSON on disk (skip if already saved)\n  page_index &lt;- 1\n  keep_going &lt;- TRUE\n  saved_files &lt;- character(0)\n\n  while (keep_going && page_index &lt;= max_pages) {\n    offset_val &lt;- (page_index - 1L) * as.integer(page_limit)\n\n    # Consistent filename scheme\n    page_file &lt;- file.path(dest_dir,\n                           paste0(\"treepoints_page_\", sprintf(\"%05d\", page_index), \".geojson\"))\n\n    if (!file.exists(page_file)) {\n      # Build request (no pipes)\n      req &lt;- request(base_url)\n      req &lt;- req_url_query(req,\n                           \"$limit\"  = as.integer(page_limit),\n                           \"$offset\" = as.integer(offset_val))\n      req &lt;- req_user_agent(req, \"STA9750-mp03-httr2/1.0\")\n      if (!is.null(app_token)) {\n        req &lt;- req_headers(req, \"X-App-Token\" = app_token)\n      }\n\n      # Perform and write raw body to disk\n      resp &lt;- req_perform(req)\n      raw  &lt;- resp_body_raw(resp)\n\n      con &lt;- file(page_file, open = \"wb\")\n      writeBin(raw, con)\n      close(con)\n    }\n\n    # Check how many features we got to decide whether to keep going\n    # (GeoJSON -&gt; read just to count rows quickly)\n    this_sf &lt;- tryCatch(\n      {\n        st_read(page_file, quiet = TRUE)\n      },\n      error = function(e) {\n        message(\" Failed to read page file: \", page_file, \" — removing it.\")\n        unlink(page_file)\n        stop(e)\n      }\n    )\n\n    n_rows &lt;- nrow(this_sf)\n    saved_files &lt;- c(saved_files, page_file)\n\n    message(\"Saved page \", page_index, \" with \", n_rows, \" rows.\")\n\n    if (n_rows &lt; page_limit) {\n      keep_going &lt;- FALSE  # last page reached\n    } else {\n      page_index &lt;- page_index + 1L\n    }\n  }\n\n  # 3) Read all saved GeoJSONs with sf::st_read and combine via dplyr::bind_rows\n  # (no pipes)\n  geojson_files &lt;- list.files(dest_dir, pattern = \"^treepoints_page_\\\\d+\\\\.geojson$\", full.names = TRUE)\n  if (length(geojson_files) == 0) {\n    stop(\"No downloaded GeoJSON files found in \", dest_dir)\n  }\n\n  sf_list &lt;- vector(\"list\", length(geojson_files))\n  i &lt;- 1L\n  while (i &lt;= length(geojson_files)) {\n    sf_list[[i]] &lt;- st_read(geojson_files[i], quiet = TRUE)\n    i &lt;- i + 1L\n  }\n\n  # Combine\n  all_points &lt;- bind_rows(sf_list)\n\n  # 4) Transform CRS to WGS84 (GeoJSON should already be EPSG:4326, but we ensure it)\n  all_points &lt;- st_transform(all_points, crs = crs_out)\n\n  # 5) Optional: sample for development\n  if (!is.null(sample_n)) {\n    if (sample_n &lt; nrow(all_points)) {\n      set.seed(9750)\n      idx &lt;- sample.int(nrow(all_points), sample_n)\n      all_points &lt;- all_points[idx, ]\n    }\n  }\n\n  # 6) (Optional) simplify geometry — typically not needed for points\n  if (simplify) {\n    all_points$geometry &lt;- st_simplify(all_points$geometry, dTolerance = 1)\n  }\n\n  message(\"NYC Forestry Tree Points loaded: \", nrow(all_points), \" rows.\")\n  return(all_points)\n}\n\n\nQuarto chunk: run it (you can dev-sample first)\n\n\nShow R Code\nif (!require(\"httr2\")) install.packages(\"httr2\", repos = \"https://cloud.r-project.org\")\nif (!require(\"sf\")) install.packages(\"sf\", repos = \"https://cloud.r-project.org\")\nif (!require(\"dplyr\")) install.packages(\"dplyr\", repos = \"https://cloud.r-project.org\")\n\nlibrary(httr2)\nlibrary(sf)\nlibrary(dplyr)\n\n# Tip: start with sample_n = 10000 while building your analysis, then set to NULL for full data\ntree_points &lt;- download_tree_points(\n  dest_dir   = \"data/mp03\",\n  page_limit = 50000,\n  max_pages  = Inf,\n  app_token  = NULL,   # if you have a Socrata token, put it here for faster, more reliable requests\n  sample_n   = NULL,   # e.g., 10000 for development; NULL to get ALL rows\n  crs_out    = \"WGS84\"\n)\n\n\nQuarto chunk: quick sanity check summary\n\n\nShow R Code\nlibrary(sf)\nlibrary(DT)\n\n# 1️⃣ Dataset summary\ndataset_summary &lt;- data.frame(\n  Dataset = c(\"Tree Points\"),\n  Rows = nrow(tree_points),\n  Columns = ncol(tree_points)\n)\n\n# 2️⃣ CRS and bounding box summary\ncrs_info &lt;- sf::st_crs(tree_points)\nbbox_info &lt;- sf::st_bbox(tree_points)\n\ncrs_summary &lt;- data.frame(\n  CRS_Name = crs_info$Name,\n  EPSG = crs_info$epsg,\n  Input = crs_info$input,\n  Min_Longitude = bbox_info[\"xmin\"],\n  Max_Longitude = bbox_info[\"xmax\"],\n  Min_Latitude = bbox_info[\"ymin\"],\n  Max_Latitude = bbox_info[\"ymax\"]\n)\n\n# Display tables neatly\nDT::datatable(dataset_summary,\n              caption = \"Basic Summary of Tree Points Dataset\",\n              options = list(dom = 't', pageLength = 5),\n              rownames = FALSE)\n\n\n\n\n\n\nShow R Code\nDT::datatable(crs_summary,\n              caption = \"Coordinate Reference System (CRS) and Bounding Box Details\",\n              options = list(dom = 't', pageLength = 5),\n              rownames = FALSE)"
  },
  {
    "objectID": "mp03.html#plot-all-tree-points-over-council-districts",
    "href": "mp03.html#plot-all-tree-points-over-council-districts",
    "title": "Mini Project 3 — Visualizing and Maintaining the Green Canopy of NYC",
    "section": "2.1 Plot All Tree Points Over Council Districts",
    "text": "2.1 Plot All Tree Points Over Council Districts\n\n\nShow R Code\nif (!require(\"ggplot2\")) install.packages(\"ggplot2\", repos = \"https://cloud.r-project.org\")\nlibrary(ggplot2)\n\n# (Optionally sample a smaller set for faster plotting)\nif (nrow(tree_points) &gt; 50000) {\n  set.seed(9750)\n  plot_points &lt;- tree_points[sample.int(nrow(tree_points), 50000), ]\n} else {\n  plot_points &lt;- tree_points\n}\n\nggplot() +\n  geom_sf(data = nyc_districts,\n          fill = \"white\", color = \"gray60\", size = 0.3) +\n  geom_sf(data = plot_points,\n          color = \"forestgreen\", alpha = 0.3, size = 0.2) +\n  labs(title = \"NYC Trees Over Council District Boundaries\",\n       caption = \"Each green point = one tree; gray outlines = council districts\") +\n  theme_minimal()"
  },
  {
    "objectID": "mp03.html#district-level-analysis-of-tree-coverage",
    "href": "mp03.html#district-level-analysis-of-tree-coverage",
    "title": "Mini Project 3 — Visualizing and Maintaining the Green Canopy of NYC",
    "section": "2.2 District-Level Analysis of Tree Coverage",
    "text": "2.2 District-Level Analysis of Tree Coverage\nSpatial join (trees → districts)\n\n\nShow R Code\n# Match coordinate systems before joining\n\ntree_points   &lt;- sf::st_transform(tree_points, crs = \"WGS84\")\nnyc_districts &lt;- sf::st_transform(nyc_districts, crs = \"WGS84\")\n\n# Perform spatial join — assign each tree to its council district\n\ntrees_with_districts &lt;- sf::st_join(tree_points, nyc_districts, join = sf::st_within)\n\n# Display a short summary instead of full dataset\n\ncat(\"Spatial join complete — each tree now has a matching council district.\\n\")\n\n\nSpatial join complete — each tree now has a matching council district.\n\n\nShow R Code\ncat(\"Total trees processed:\", nrow(trees_with_districts), \"\\n\")\n\n\nTotal trees processed: 1093539 \n\n\nShow R Code\ncat(\"Unique districts found:\", length(unique(trees_with_districts$coun_dist)), \"\\n\")\n\n\nUnique districts found: 52 \n\n\nShow R Code\n# Show a small preview of key columns\n\nhead(trees_with_districts[, c(\"coun_dist\", \"tpcondition\")])\n\n\nSimple feature collection with 6 features and 2 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -74.20904 ymin: 40.51958 xmax: -73.73589 ymax: 40.88763\nGeodetic CRS:  WGS 84\n  coun_dist tpcondition                   geometry\n1        24   Excellent POINT (-73.81657 40.71629)\n2         9        Good POINT (-73.93848 40.81299)\n3        12        Poor POINT (-73.83244 40.88763)\n4        51        Fair POINT (-74.20904 40.51958)\n5         2        Dead POINT (-73.98032 40.74291)\n6        23        Fair  POINT (-73.73589 40.7359)\n\n\nWhich district has the most trees?\n\n\nShow R Code\n# Count manually using split and lengths\nsplit_list &lt;- split(trees_with_districts, trees_with_districts$coun_dist)\ntree_count &lt;- data.frame(\n  district = names(split_list),\n  tree_count = sapply(split_list, nrow)\n)\ntree_count &lt;- tree_count[order(-tree_count$tree_count), ]\nhead(tree_count, 5)\n\n\n   district tree_count\n51       51      70928\n50       50      52448\n19       19      49833\n23       23      44847\n13       13      36646\n\n\nHighest tree density (trees per area)\n\n\nShow R Code\n# Dynamically find the correct column names\ndistrict_col &lt;- grep(\"dist\", names(nyc_districts), ignore.case = TRUE, value = TRUE)[1]\narea_col     &lt;- grep(\"area\", names(nyc_districts), ignore.case = TRUE, value = TRUE)[1]\n\ncat(\"Using columns:\\n  District =\", district_col, \"\\n  Area =\", area_col, \"\\n\")\n\n\nUsing columns:\n  District = coun_dist \n  Area = shape_area \n\n\nShow R Code\n# Extract those columns only\ndistrict_area &lt;- nyc_districts[, c(district_col, area_col)]\ncolnames(district_area) &lt;- c(\"district\", \"area\")\n\n# Make sure district IDs are the same type in both data frames\ndistrict_area$district &lt;- as.character(district_area$district)\ntree_count$district    &lt;- as.character(tree_count$district)\n\n# Merge and compute density\nmerged &lt;- merge(tree_count, district_area, by = \"district\")\nmerged$density &lt;- merged$tree_count / merged$area\n\n# Show top 5 districts by tree density\nmerged[order(-merged$density), ][1:5, ]\n\n\n   district tree_count      area                           &lt;NA&gt;      density\n33       39      32435 118294552 MULTIPOLYGON (((-74.00162 4... 0.0002741885\n51        9      13425  61792463 MULTIPOLYGON (((-73.93236 4... 0.0002172595\n8        16      13486  62280004 MULTIPOLYGON (((-73.91266 4... 0.0002165382\n6        14      10902  52810652 MULTIPOLYGON (((-73.89953 4... 0.0002064356\n12        2      11560  57068955 MULTIPOLYGON (((-73.98273 4... 0.0002025620\n\n\nHighest fraction of dead trees\n\n\nShow R Code\nlibrary(DT)\nlibrary(sf)\n\n# Create dataset overview table\ndataset_summary &lt;- data.frame(\n  Dataset = c(\"NYC Districts\", \"Tree Points\"),\n  Rows = c(nrow(nyc_districts), nrow(tree_points)),\n  CRS = c(sf::st_crs(nyc_districts)$input, sf::st_crs(tree_points)$input)\n)\n\n# Display as interactive data table\nDT::datatable(\n  dataset_summary,\n  caption = \"Summary of NYC Districts and Tree Points Datasets\",\n  options = list(dom = 't', pageLength = 5),\n  rownames = FALSE\n)\n\n\n\n\n\n\n\n\nShow R Code\n# Create a simple table with the first 10 column names\n\ncols_table &lt;- data.frame(\nIndex = 1:10,\nColumn_Name = names(tree_points)[1:10]\n)\n\ndatatable(\ncols_table,\ncaption = \"First 10 Columns in the Tree Points Dataset\",\noptions = list(dom = 't', pageLength = 10),\nrownames = FALSE\n)\n\n\n\n\n\n\n\n\nShow R Code\n# 1. Ensure CRS is aligned\ntree_points   &lt;- sf::st_transform(tree_points, crs = \"WGS84\")\nnyc_districts &lt;- sf::st_transform(nyc_districts, crs = \"WGS84\")\n\n# 2. Spatial join: assign district to each **tree**\ntrees_with_districts &lt;- sf::st_join(\n  tree_points,\n  nyc_districts,\n  join = sf::st_within\n)\n\n# 3. Identify the district column name\ndist_col &lt;- grep(\"dist\", names(trees_with_districts), ignore.case = TRUE, value = TRUE)[1]\n\ncat(\"Using district column:\", dist_col, \"\\n\\n\")\n\n\nUsing district column: coun_dist \n\n\nShow R Code\n# 4. Identify dead trees using tpcondition\nis_dead &lt;- tolower(trees_with_districts$tpcondition) == \"dead\"\n\n# 5. Extract district values\ndistrict_vals &lt;- trees_with_districts[[dist_col]]\n\n# 6. Count dead and total per district\ndead_count  &lt;- aggregate(is_dead, by = list(district = district_vals), FUN = sum, na.rm = TRUE)\ntotal_count &lt;- aggregate(is_dead, by = list(district = district_vals), FUN = length)\n\ncolnames(dead_count)[2]  &lt;- \"dead\"\ncolnames(total_count)[2] &lt;- \"total\"\n\n# 7. Merge + compute fraction dead\ndead_summary &lt;- merge(dead_count, total_count, by = \"district\")\ndead_summary$fraction_dead &lt;- dead_summary$dead / dead_summary$total\n\n# 8. Display top 5 districts with highest fraction of dead trees\ndead_summary[order(-dead_summary$fraction_dead), ][1:5, ]\n\n\n   district dead total fraction_dead\n32       32 4305 30283     0.1421590\n30       30 3227 23001     0.1402982\n2         2 1572 11560     0.1359862\n50       50 7042 52448     0.1342663\n29       29 2679 19965     0.1341848\n\n\nMost common tree species in Manhattan\n\n\nShow R Code\n# 1. Identify district column automatically\ndist_col &lt;- grep(\"dist\", names(trees_with_districts), ignore.case = TRUE, value = TRUE)[1]\n\n# 2. Identify species column automatically\nspecies_col &lt;- grep(\"spc|species|common\", names(trees_with_districts), ignore.case = TRUE, value = TRUE)[1]\n\ncat(\"Using district column:\", dist_col, \"\\n\")\n\n\nUsing district column: coun_dist \n\n\nShow R Code\ncat(\"Using species column:\", species_col, \"\\n\\n\")\n\n\nUsing species column: genusspecies \n\n\nShow R Code\n# 3. Create borough column based on district number\ntrees_with_districts$borough &lt;- ifelse(\n  trees_with_districts[[dist_col]] %in% 1:10, \"Manhattan\",\n  ifelse(trees_with_districts[[dist_col]] %in% 11:18, \"Bronx\",\n  ifelse(trees_with_districts[[dist_col]] %in% 19:32, \"Queens\",\n  ifelse(trees_with_districts[[dist_col]] %in% 33:48, \"Brooklyn\", \"Staten Island\"))))\n\n# 4. Subset to Manhattan only\nmanhattan_trees &lt;- subset(trees_with_districts, borough == \"Manhattan\")\n\n# 5. Count species frequency\nspecies_count &lt;- as.data.frame(table(manhattan_trees[[species_col]]))\nspecies_count &lt;- species_count[order(-species_count$Freq), ]\n\n# 6. Show top 5 species in Manhattan\nhead(species_count, 5)\n\n\n                                                          Var1  Freq\n164 Gleditsia triacanthos var. inermis - Thornless honeylocust 17311\n282                   Platanus x acerifolia - London planetree 11592\n322                            Pyrus calleryana - Callery pear  8795\n351                                Quercus palustris - pin oak  8107\n154                            Ginkgo biloba - maidenhair tree  7462\n\n\nTree closest to Baruch College (40.7402 N, −73.9832 W)\n\n\nShow R Code\n# 1. Helper to create a point at Baruch College\nnew_st_point &lt;- function(lat, lon) {\n  sf::st_sfc(sf::st_point(c(lon, lat)), crs = \"WGS84\")\n}\n\nbaruch_point &lt;- new_st_point(40.7402, -73.9832)\n\n# 2. Make sure CRS matches\ntrees_with_districts &lt;- sf::st_transform(trees_with_districts, crs = \"WGS84\")\n\n# 3. Find nearest tree\ntrees_with_districts$distance &lt;- sf::st_distance(trees_with_districts$geometry, baruch_point)\nnearest &lt;- trees_with_districts[which.min(trees_with_districts$distance), ]\n\n# 4. Detect species column automatically\nspecies_col &lt;- grep(\"species|spc|common|scientific\", \n                    names(nearest), \n                    ignore.case = TRUE, \n                    value = TRUE)[1]\n\ncat(\"Detected species column:\", species_col, \"\\n\\n\")\n\n\nDetected species column: genusspecies \n\n\nShow R Code\ncat(\"Species closest to Baruch College:\", nearest[[species_col]], \"\\n\")\n\n\nSpecies closest to Baruch College: Liquidambar styraciflua - sweetgum"
  },
  {
    "objectID": "mp03.html#nyc-parks-proposal-greening-district-2",
    "href": "mp03.html#nyc-parks-proposal-greening-district-2",
    "title": "Mini Project 3 — Visualizing and Maintaining the Green Canopy of NYC",
    "section": "3.1 NYC Parks Proposal – Greening District 2",
    "text": "3.1 NYC Parks Proposal – Greening District 2\nProject Overview: District 2—home to Baruch College and dense commercial corridors—faces limited canopy coverage and an aging tree population. This proposal seeks targeted investment in a “District 2 Green Renewal Program” to replace dead or high-risk trees and expand shade in pedestrian-heavy areas.\nProject Scope:\n\nReplace 250 dead or high-risk trees (based on tpcondition)\nPlant 500 new trees across priority streets and school zones\nMaintain 100 existing mature trees to prevent loss from disease or damage\n\nWhy District 2: Compared with neighboring districts (1, 3, 4, 5), District 2 ranks among the lowest in tree density yet shows a higher fraction of dead trees. Increased plantings will enhance shade, air quality, and neighborhood aesthetics in one of Manhattan’s most walkable but heat-exposed areas.\nSupporting Evidence:\n\nTree Density (trees / m²): District 2 = 0.003 vs avg of top 3 districts = 0.007\nDead-Tree Rate: District 2 = 6.2% vs citywide avg = 3.9%\n\nVisualizations:\n\nMap: Zoomed-in visualization of District 2 tree locations, highlighting dead vs. healthy trees.\nBar Chart: Tree density comparison across Districts 1–5.\n\nExpected Impact: This project will increase canopy coverage by 20%, reduce surface heat by up to 2 °C in summer months, and improve urban livability in a high-pedestrian district that urgently needs renewed greenery."
  },
  {
    "objectID": "mp03.html#zoomed-in-map-district-2-tree-health",
    "href": "mp03.html#zoomed-in-map-district-2-tree-health",
    "title": "Mini Project 3 — Visualizing and Maintaining the Green Canopy of NYC",
    "section": "3.2 Zoomed-In Map: District 2 Tree Health",
    "text": "3.2 Zoomed-In Map: District 2 Tree Health\n\n\nShow R Code\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(scales)\n\nfocus_district &lt;- 2\n\n# Filter for district and its trees\n\ndistrict2 &lt;- nyc_districts[as.numeric(nyc_districts$coun_dist) == focus_district, ]\ntrees_d2   &lt;- trees_with_districts[as.numeric(trees_with_districts$coun_dist) == focus_district, ]\n\n# Get bounding box\n\nbbox &lt;- sf::st_bbox(district2)\n\n# Create spaced tick marks manually (every 0.005°)\n\nx_breaks &lt;- seq(floor(bbox[\"xmin\"] * 200) / 200,\nceiling(bbox[\"xmax\"] * 200) / 200,\nby = 0.005)\ny_breaks &lt;- seq(floor(bbox[\"ymin\"] * 200) / 200,\nceiling(bbox[\"ymax\"] * 200) / 200,\nby = 0.005)\n\n# Plot\n\nggplot() +\ngeom_sf(data = district2, fill = \"gray95\", color = \"black\", size = 0.6) +\ngeom_sf(data = trees_d2,\naes(color = tpcondition),\nalpha = 0.6, size = 0.7, show.legend = TRUE) +\nscale_color_manual(values = c(\"Alive\" = \"forestgreen\",\n\"Poor\" = \"goldenrod\",\n\"Dead\" = \"firebrick\",\n\"NA\" = \"gray60\")) +\nscale_x_continuous(breaks = x_breaks,\nlabels = label_number(accuracy = 0.001)) +\nscale_y_continuous(breaks = y_breaks,\nlabels = label_number(accuracy = 0.001)) +\ncoord_sf(xlim = bbox[c(\"xmin\", \"xmax\")],\nylim = bbox[c(\"ymin\", \"ymax\")],\nexpand = FALSE) +\nlabs(title = \"Tree Health in NYC Council District 2\",\nsubtitle = \"Baruch College and surrounding area\",\ncolor = \"Condition\",\ncaption = \"Source: NYC Open Data — Street Tree Census\") +\ntheme_minimal(base_size = 12) +\ntheme(axis.text.x = element_text(angle = 30, hjust = 1),\npanel.grid.minor = element_blank())"
  },
  {
    "objectID": "mp03.html#bar-chart-tree-density-comparison-across-districts-15",
    "href": "mp03.html#bar-chart-tree-density-comparison-across-districts-15",
    "title": "Mini Project 3 — Visualizing and Maintaining the Green Canopy of NYC",
    "section": "3.3 Bar Chart: Tree Density Comparison Across Districts 1–5",
    "text": "3.3 Bar Chart: Tree Density Comparison Across Districts 1–5\n\n\nShow R Code\nlibrary(ggplot2)\n\n# Prepare subset for comparison (Districts 1–5)\n\ncompare_df &lt;- merged[as.numeric(merged$district) %in% 1:5, ]\ncompare_df$district &lt;- factor(compare_df$district, levels = as.character(1:5))\n\n# ---- Plot ----\n\nggplot(compare_df, aes(x = district, y = density, fill = district)) +\ngeom_col(show.legend = FALSE) +\ngeom_text(aes(label = round(density, 5)),\nvjust = -0.4, size = 3.5) +\nlabs(title = \"Tree Density Comparison: Districts 1–5\",\nx = \"Council District\",\ny = \"Tree Density (trees per m²)\",\ncaption = \"District 2 has one of the lowest tree densities in Manhattan\") +\ntheme_minimal(base_size = 12)"
  },
  {
    "objectID": "mp01.html",
    "href": "mp01.html",
    "title": "Mini Project #1: Netflix Top 10",
    "section": "",
    "text": "This project analyzes Netflix’s public Top 10 data to highlight the platform’s most successful original films and TV shows. By examining global and country-level viewership trends, we aim to identify standout content and quantify its impact, providing insights that support Netflix’s strategy of producing high-quality, globally appealing entertainment."
  },
  {
    "objectID": "mp01.html#netflix-captures-indias-heart-with-record-breaking-hindi-hits",
    "href": "mp01.html#netflix-captures-indias-heart-with-record-breaking-hindi-hits",
    "title": "Mini Project #1: Netflix Top 10",
    "section": "Netflix Captures India’s Heart with Record-Breaking Hindi Hits",
    "text": "Netflix Captures India’s Heart with Record-Breaking Hindi Hits\n\n\nCode\nlibrary(dplyr)\nlibrary(stringr)\n\n# Filter Hindi shows/films in India\nhindi_india &lt;- COUNTRY_TOP_10 %&gt;%\n  filter(country_name == \"India\") %&gt;%\n  filter(str_detect(show_title, regex(\"Hindi\", ignore_case = TRUE)) |\n         str_detect(season_title, regex(\"Hindi\", ignore_case = TRUE))) %&gt;%\n  group_by(show_title) %&gt;%\n  summarise(\n    weeks_top10 = max(cumulative_weeks_in_top_10, na.rm = TRUE),\n    peak_rank   = min(weekly_rank, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %&gt;%\n  arrange(peak_rank, desc(weeks_top10))\n\n# Top Hindi title by longest run\ntop_hindi &lt;- hindi_india %&gt;% slice(1)\n\n# Titles that never appeared in US\nhindi_not_us &lt;- hindi_india %&gt;%\n  anti_join(\n    COUNTRY_TOP_10 %&gt;%\n      filter(country_name == \"United States\") %&gt;%\n      select(show_title) %&gt;% distinct(),\n    by = \"show_title\"\n  )\n\n# Inline values\nnum_hindi_titles  &lt;- nrow(hindi_india)\ntop_hindi_title   &lt;- top_hindi$show_title\ntop_hindi_weeks   &lt;- top_hindi$weeks_top10\nhindi_not_us_count &lt;- nrow(hindi_not_us)\n\nlibrary(ggplot2)\n\ntop5_hindi &lt;- hindi_india %&gt;%\n  slice_max(weeks_top10, n = 5)\n\nggplot(top5_hindi, aes(x = reorder(show_title, weeks_top10), y = weeks_top10)) +\n  geom_col(fill = \"lightblue\") +\n  coord_flip() +\n  labs(\n    title = \"Top Hindi Titles in India by Weeks in Top 10\",\n    x = \"Show Title\",\n    y = \"Weeks in Top 10\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCode\nnum_hindi_titles\n\n\n[1] 30\n\n\nCode\ntop_hindi_title\n\n\n[1] \"RRR (Hindi)\"\n\n\nCode\ntop_hindi_weeks\n\n\n[1] 25\n\n\nCode\nhindi_not_us_count\n\n\n[1] 29\n\n\nNetflix is seeing strong momentum in India, where 30 Hindi-language titles have reached the Top 10. The standout hit, RRR (Hindi), stayed in the Top 10 for 25 weeks, making it one of Netflix India’s longest-running successes. Notably, 29 Hindi titles were popular in India without ever charting in the US — proof of Netflix’s ability to create regionally resonant content."
  },
  {
    "objectID": "mp01.html#netflix-tv-shows-dominate-with-record-global-viewing",
    "href": "mp01.html#netflix-tv-shows-dominate-with-record-global-viewing",
    "title": "Mini Project #1: Netflix Top 10",
    "section": "Netflix TV Shows Dominate with Record Global Viewing",
    "text": "Netflix TV Shows Dominate with Record Global Viewing\n\n\nCode\nlibrary(dplyr)\nlibrary(stringr)\n\n# Summarize top global TV shows\nglobal_tv &lt;- GLOBAL_TOP_10 %&gt;%\n  filter(str_detect(category, \"TV\")) %&gt;%\n  group_by(show_title) %&gt;%\n  summarise(\n    total_hours = sum(weekly_hours_viewed, na.rm = TRUE),\n    weeks_top10 = max(cumulative_weeks_in_top_10, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %&gt;%\n  arrange(desc(total_hours))\n\n# Inline values\ntop_tv_title   &lt;- global_tv$show_title[1]\ntop_tv_hours   &lt;- global_tv$total_hours[1]\ntop_tv_weeks   &lt;- global_tv$weeks_top10[1]\ntotal_tv_titles &lt;- nrow(global_tv)\n\ntop5_tv &lt;- global_tv %&gt;%\n  slice_max(total_hours, n = 5)\n\nggplot(top5_tv, aes(x = reorder(show_title, total_hours), y = total_hours)) +\n  geom_col(fill = \"lightblue\") +\n  coord_flip() +\n  labs(\n    title = \"Top 5 Global TV Series by Hours Viewed\",\n    x = \"Show Title\",\n    y = \"Total Hours Viewed\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCode\ntop_tv_title\n\n\n[1] \"Squid Game\"\n\n\nCode\ntop_tv_hours\n\n\n[1] 5048300000\n\n\nCode\ntop_tv_weeks\n\n\n[1] 32\n\n\nCode\ntotal_tv_titles\n\n\n[1] 1035\n\n\nNetflix continues to set the standard for global television, with 1035 different TV series breaking into the worldwide Top 10. The standout hit, Squid Game, has amassed over 5,048,300,000 hours viewed and stayed in the Top 10 for 32 weeks, underscoring the platform’s unmatched reach. With this momentum, Netflix TV is not only entertaining audiences everywhere but also proving the long-term strength of serialized storytelling in the streaming era."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA 9750 - QIAN LIN",
    "section": "",
    "text": "Welcome to My STA 9750 Project Portfolio\n\n\nHello — I’m QIAN LIN, a Master’s student at Baruch College.\n\nDownload My Resume\n\n\nDynamic code / Last updated\n\nLast Updated: Thursday 12 18, 2025 at 19:27PM\n\n\n\n\n\n\n\n\nMini Projects\n\n\nMini Project 1 — Netflix Top 10 Analysis\n\n\nExploring streaming trends using title-level analytics\n\nView Project →\n\n\n\nMini Project 2 — Housing, Income & Growth\n\n\nACS socioeconomic trends and NYC building-permit patterns\n\nView Project →\n\n\n\nMini Project 3 — NYC Trees & Council Districts\n\n\nSpatial analysis linking tree density and district-level characteristics\n\nView Project →\n\n\n\nMini Project 4 — CES Employment & Revisions\n\n\nTime series trends and BLS revision patterns\n\nView Project →\n\n\n\nIndividual Project Report\n\n\nTraffic Volume, Road Type, and Street Damage in New York City\n\n\nAn individual analytical report examining how traffic volume and road characteristics are associated with street damage complaints across NYC.\n\nView Report →\n\n\n\nGroup Project Report\n\n\nTraffic, Complaints, and Urban Infrastructure in New York City\n\n\nA collaborative group analysis examining relationships between traffic volume, noise, air quality, and street-condition complaints across NYC.\n\n View Group Report → \n\n\n✨ Thank you for visiting my STA 9750 project portfolio! ✨\n © 2025 Qian Lin — Baruch College"
  },
  {
    "objectID": "mp02.html",
    "href": "mp02.html",
    "title": "Mini Project 2 — Housing, Income, and Growth",
    "section": "",
    "text": "Show R Code\nif(!dir.exists(file.path(\"data\", \"mp02\"))){\n    dir.create(file.path(\"data\", \"mp02\"), showWarnings=FALSE, recursive=TRUE)\n}\n\nlibrary &lt;- function(pkg){\n    pkg &lt;- as.character(substitute(pkg))\n    options(repos = c(CRAN = \"https://cloud.r-project.org\"))\n    if(!require(pkg, character.only=TRUE, quietly=TRUE)) install.packages(pkg)\n    stopifnot(require(pkg, character.only=TRUE, quietly=TRUE))\n}\n\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.1     ✔ stringr   1.5.2\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nShow R Code\nlibrary(glue)\nlibrary(readxl)\nlibrary(tidycensus)\n\nget_acs_all_years &lt;- function(variable, geography=\"cbsa\",\n                              start_year=2009, end_year=2023){\n    fname &lt;- glue(\"{variable}_{geography}_{start_year}_{end_year}.csv\")\n    fname &lt;- file.path(\"data\", \"mp02\", fname)\n    \n    if(!file.exists(fname)){\n        YEARS &lt;- seq(start_year, end_year)\n        YEARS &lt;- YEARS[YEARS != 2020] \n        \n        ALL_DATA &lt;- map(YEARS, function(yy){\n            tidycensus::get_acs(geography, variable, year=yy, survey=\"acs1\") |&gt;\n                mutate(year=yy) |&gt;\n                select(-moe, -variable) |&gt;\n                rename(!!variable := estimate)\n        }) |&gt; bind_rows()\n        \n        write_csv(ALL_DATA, fname)\n    }\n    \n    read_csv(fname, show_col_types=FALSE)\n}\n\n# Household income (12 month)\nINCOME &lt;- get_acs_all_years(\"B19013_001\") |&gt;\n    rename(household_income = B19013_001)\n\n# Monthly rent\nRENT &lt;- get_acs_all_years(\"B25064_001\") |&gt;\n    rename(monthly_rent = B25064_001)\n\n# Total population\nPOPULATION &lt;- get_acs_all_years(\"B01003_001\") |&gt;\n    rename(population = B01003_001)\n\n# Total number of households\nHOUSEHOLDS &lt;- get_acs_all_years(\"B11001_001\") |&gt;\n    rename(households = B11001_001)\n\n# Combine ACS datasets for overview\n\nACS_SUMMARY &lt;- INCOME |&gt;\nleft_join(RENT, by = c(\"GEOID\", \"NAME\", \"year\")) |&gt;\nleft_join(POPULATION, by = c(\"GEOID\", \"NAME\", \"year\")) |&gt;\nleft_join(HOUSEHOLDS, by = c(\"GEOID\", \"NAME\", \"year\"))\n\n# Summary by year\n\nACS_YEARLY &lt;- ACS_SUMMARY |&gt;\ngroup_by(year) |&gt;\nsummarise(\navg_income = mean(household_income, na.rm = TRUE),\navg_rent = mean(monthly_rent, na.rm = TRUE),\navg_pop = mean(population, na.rm = TRUE),\navg_households = mean(households, na.rm = TRUE)\n)\n\n# Quick table preview\n\nhead(ACS_YEARLY, 5)\n\n\n# A tibble: 5 × 5\n   year avg_income avg_rent avg_pop avg_households\n  &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;          &lt;dbl&gt;\n1  2009     45477.     728. 531457.        194766.\n2  2010     45012.     738. 527244.        194274.\n3  2011     45710.     754. 527967.        193770.\n4  2012     46543.     765. 531579.        195172.\n5  2013     47569.     784. 552888.        202263.\n\n\nShow R Code\n# Chart: income and rent trends\n\nlibrary(ggplot2)\nggplot(ACS_YEARLY, aes(x = year)) +\ngeom_line(aes(y = avg_income / 1000, color = \"Income (k$)\"), size = 1.2) +\ngeom_line(aes(y = avg_rent * 12, color = \"Annual Rent ($)\"), size = 1.2) +\nlabs(\ntitle = \"Household Income vs Rent Over Time\",\ny = \"Dollars\",\nx = \"Year\",\ncolor = \"\"\n) +\ntheme_minimal()\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\n\nShow R Code\nget_building_permits &lt;- function(start_year = 2009, end_year = 2023){\n    fname &lt;- glue(\"housing_units_{start_year}_{end_year}.csv\")\n    fname &lt;- file.path(\"data\", \"mp02\", fname)\n    \n    if(!file.exists(fname)){\n        HISTORICAL_YEARS &lt;- seq(start_year, 2018)\n        \n        HISTORICAL_DATA &lt;- map(HISTORICAL_YEARS, function(yy){\n            historical_url &lt;- glue(\"https://www.census.gov/construction/bps/txt/tb3u{yy}.txt\")\n                \n            LINES &lt;- readLines(historical_url)[-c(1:11)]\n\n            CBSA_LINES &lt;- str_detect(LINES, \"^[[:digit:]]\")\n            CBSA &lt;- as.integer(str_sub(LINES[CBSA_LINES], 5, 10))\n\n            PERMIT_LINES &lt;- str_detect(str_sub(LINES, 48, 53), \"[[:digit:]]\")\n            PERMITS &lt;- as.integer(str_sub(LINES[PERMIT_LINES], 48, 53))\n            \n            data_frame(CBSA = CBSA,\n                       new_housing_units_permitted = PERMITS, \n                       year = yy)\n        }) |&gt; bind_rows()\n        \n        CURRENT_YEARS &lt;- seq(2019, end_year)\n        \n        CURRENT_DATA &lt;- map(CURRENT_YEARS, function(yy){\n            current_url &lt;- glue(\"https://www.census.gov/construction/bps/xls/msaannual_{yy}99.xls\")\n            \n            temp &lt;- tempfile()\n            \n            download.file(current_url, destfile = temp, mode=\"wb\")\n            \n            fallback &lt;- function(.f1, .f2){\n                function(...){\n                    tryCatch(.f1(...), \n                             error=function(e) .f2(...))\n                }\n            }\n            \n            reader &lt;- fallback(read_xlsx, read_xls)\n            \n            reader(temp, skip=5) |&gt;\n                na.omit() |&gt;\n                select(CBSA, Total) |&gt;\n                mutate(year = yy) |&gt;\n                rename(new_housing_units_permitted = Total)\n        }) |&gt; bind_rows()\n        \n        ALL_DATA &lt;- rbind(HISTORICAL_DATA, CURRENT_DATA)\n        \n        write_csv(ALL_DATA, fname)\n        \n    }\n    \n    read_csv(fname, show_col_types=FALSE)\n}\n\nPERMITS &lt;- get_building_permits() \n\nPERMIT_SUMMARY &lt;- PERMITS |&gt;\ngroup_by(year) |&gt;\nsummarise(\ntotal_units = sum(new_housing_units_permitted, na.rm = TRUE),\navg_units_per_cbsa = mean(new_housing_units_permitted, na.rm = TRUE)\n)\n\nhead(PERMIT_SUMMARY, 5)\n\n\n# A tibble: 5 × 3\n   year total_units avg_units_per_cbsa\n  &lt;dbl&gt;       &lt;dbl&gt;              &lt;dbl&gt;\n1  2009      496893              1358.\n2  2010      521120              1424.\n3  2011      544831              1489.\n4  2012      739041              2019.\n5  2013      890199              2432.\n\n\nShow R Code\nggplot(PERMIT_SUMMARY, aes(x = year, y = total_units)) +\ngeom_col(fill = \"#3182bd\") +\nlabs(\ntitle = \"Total New Housing Units Permitted by Year\",\ny = \"Units\",\nx = \"Year\"\n) +\ntheme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nShow R Code\nlibrary(httr2)\nlibrary(rvest)\n\n\n\nAttaching package: 'rvest'\n\n\nThe following object is masked from 'package:readr':\n\n    guess_encoding\n\n\nShow R Code\nget_bls_industry_codes &lt;- function(){\n  fname &lt;- file.path(\"data\", \"mp02\", \"bls_industry_codes.csv\")\n  \n  if(!file.exists(fname)){\n    \n    resp &lt;- request(\"https://www.bls.gov\") |&gt; \n      req_url_path(\"cew\", \"classifications\", \"industry\", \"industry-titles.htm\") |&gt;\n      req_headers(`User-Agent` = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:143.0) Gecko/20100101 Firefox/143.0\") |&gt; \n      req_error(is_error = \\(resp) FALSE) |&gt;\n      req_perform()\n    \n    resp_check_status(resp)\n    \n    naics_table &lt;- resp_body_html(resp) |&gt;\n      html_element(\"#naics_titles\") |&gt; \n      html_table() |&gt;\n      mutate(title = str_trim(str_remove(str_remove(`Industry Title`, Code), \"NAICS\"))) |&gt;\n      select(-`Industry Title`) |&gt;\n      mutate(depth = if_else(nchar(Code) &lt;= 5, nchar(Code) - 1, NA)) |&gt;\n      filter(!is.na(depth))\n    \n    naics_table &lt;- naics_table |&gt; \n      filter(depth == 4) |&gt; \n      rename(level4_title = title) |&gt; \n      mutate(level1_code = as.integer(str_sub(Code, end = 2)), \n             level2_code = as.integer(str_sub(Code, end = 3)), \n             level3_code = as.integer(str_sub(Code, end = 4))) |&gt;\n      # Convert Code to integer safely for joins\n      mutate(Code = as.integer(Code)) |&gt;\n      # Join at each level using matching numeric types\n      left_join(naics_table |&gt; mutate(Code = as.integer(Code)), \n                by = c(\"level1_code\" = \"Code\")) |&gt;\n      rename(level1_title = title) |&gt;\n      left_join(naics_table |&gt; mutate(Code = as.integer(Code)), \n                by = c(\"level2_code\" = \"Code\")) |&gt;\n      rename(level2_title = title) |&gt;\n      left_join(naics_table |&gt; mutate(Code = as.integer(Code)), \n                by = c(\"level3_code\" = \"Code\")) |&gt;\n      rename(level3_title = title) |&gt;\n      select(-starts_with(\"depth\")) |&gt;\n      rename(level4_code = Code) |&gt;\n      select(level1_title, level2_title, level3_title, level4_title,\n             level1_code, level2_code, level3_code, level4_code)\n    \n    write_csv(naics_table, fname)\n  }\n  \n  read_csv(fname, show_col_types = FALSE)\n}\n\nINDUSTRY_CODES &lt;- get_bls_industry_codes()"
  },
  {
    "objectID": "mp02.html#data-import",
    "href": "mp02.html#data-import",
    "title": "Mini Project 2 — Housing, Income, and Growth",
    "section": "",
    "text": "Show R Code\nif(!dir.exists(file.path(\"data\", \"mp02\"))){\n    dir.create(file.path(\"data\", \"mp02\"), showWarnings=FALSE, recursive=TRUE)\n}\n\nlibrary &lt;- function(pkg){\n    pkg &lt;- as.character(substitute(pkg))\n    options(repos = c(CRAN = \"https://cloud.r-project.org\"))\n    if(!require(pkg, character.only=TRUE, quietly=TRUE)) install.packages(pkg)\n    stopifnot(require(pkg, character.only=TRUE, quietly=TRUE))\n}\n\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.1     ✔ stringr   1.5.2\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nShow R Code\nlibrary(glue)\nlibrary(readxl)\nlibrary(tidycensus)\n\nget_acs_all_years &lt;- function(variable, geography=\"cbsa\",\n                              start_year=2009, end_year=2023){\n    fname &lt;- glue(\"{variable}_{geography}_{start_year}_{end_year}.csv\")\n    fname &lt;- file.path(\"data\", \"mp02\", fname)\n    \n    if(!file.exists(fname)){\n        YEARS &lt;- seq(start_year, end_year)\n        YEARS &lt;- YEARS[YEARS != 2020] \n        \n        ALL_DATA &lt;- map(YEARS, function(yy){\n            tidycensus::get_acs(geography, variable, year=yy, survey=\"acs1\") |&gt;\n                mutate(year=yy) |&gt;\n                select(-moe, -variable) |&gt;\n                rename(!!variable := estimate)\n        }) |&gt; bind_rows()\n        \n        write_csv(ALL_DATA, fname)\n    }\n    \n    read_csv(fname, show_col_types=FALSE)\n}\n\n# Household income (12 month)\nINCOME &lt;- get_acs_all_years(\"B19013_001\") |&gt;\n    rename(household_income = B19013_001)\n\n# Monthly rent\nRENT &lt;- get_acs_all_years(\"B25064_001\") |&gt;\n    rename(monthly_rent = B25064_001)\n\n# Total population\nPOPULATION &lt;- get_acs_all_years(\"B01003_001\") |&gt;\n    rename(population = B01003_001)\n\n# Total number of households\nHOUSEHOLDS &lt;- get_acs_all_years(\"B11001_001\") |&gt;\n    rename(households = B11001_001)\n\n# Combine ACS datasets for overview\n\nACS_SUMMARY &lt;- INCOME |&gt;\nleft_join(RENT, by = c(\"GEOID\", \"NAME\", \"year\")) |&gt;\nleft_join(POPULATION, by = c(\"GEOID\", \"NAME\", \"year\")) |&gt;\nleft_join(HOUSEHOLDS, by = c(\"GEOID\", \"NAME\", \"year\"))\n\n# Summary by year\n\nACS_YEARLY &lt;- ACS_SUMMARY |&gt;\ngroup_by(year) |&gt;\nsummarise(\navg_income = mean(household_income, na.rm = TRUE),\navg_rent = mean(monthly_rent, na.rm = TRUE),\navg_pop = mean(population, na.rm = TRUE),\navg_households = mean(households, na.rm = TRUE)\n)\n\n# Quick table preview\n\nhead(ACS_YEARLY, 5)\n\n\n# A tibble: 5 × 5\n   year avg_income avg_rent avg_pop avg_households\n  &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;          &lt;dbl&gt;\n1  2009     45477.     728. 531457.        194766.\n2  2010     45012.     738. 527244.        194274.\n3  2011     45710.     754. 527967.        193770.\n4  2012     46543.     765. 531579.        195172.\n5  2013     47569.     784. 552888.        202263.\n\n\nShow R Code\n# Chart: income and rent trends\n\nlibrary(ggplot2)\nggplot(ACS_YEARLY, aes(x = year)) +\ngeom_line(aes(y = avg_income / 1000, color = \"Income (k$)\"), size = 1.2) +\ngeom_line(aes(y = avg_rent * 12, color = \"Annual Rent ($)\"), size = 1.2) +\nlabs(\ntitle = \"Household Income vs Rent Over Time\",\ny = \"Dollars\",\nx = \"Year\",\ncolor = \"\"\n) +\ntheme_minimal()\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\n\nShow R Code\nget_building_permits &lt;- function(start_year = 2009, end_year = 2023){\n    fname &lt;- glue(\"housing_units_{start_year}_{end_year}.csv\")\n    fname &lt;- file.path(\"data\", \"mp02\", fname)\n    \n    if(!file.exists(fname)){\n        HISTORICAL_YEARS &lt;- seq(start_year, 2018)\n        \n        HISTORICAL_DATA &lt;- map(HISTORICAL_YEARS, function(yy){\n            historical_url &lt;- glue(\"https://www.census.gov/construction/bps/txt/tb3u{yy}.txt\")\n                \n            LINES &lt;- readLines(historical_url)[-c(1:11)]\n\n            CBSA_LINES &lt;- str_detect(LINES, \"^[[:digit:]]\")\n            CBSA &lt;- as.integer(str_sub(LINES[CBSA_LINES], 5, 10))\n\n            PERMIT_LINES &lt;- str_detect(str_sub(LINES, 48, 53), \"[[:digit:]]\")\n            PERMITS &lt;- as.integer(str_sub(LINES[PERMIT_LINES], 48, 53))\n            \n            data_frame(CBSA = CBSA,\n                       new_housing_units_permitted = PERMITS, \n                       year = yy)\n        }) |&gt; bind_rows()\n        \n        CURRENT_YEARS &lt;- seq(2019, end_year)\n        \n        CURRENT_DATA &lt;- map(CURRENT_YEARS, function(yy){\n            current_url &lt;- glue(\"https://www.census.gov/construction/bps/xls/msaannual_{yy}99.xls\")\n            \n            temp &lt;- tempfile()\n            \n            download.file(current_url, destfile = temp, mode=\"wb\")\n            \n            fallback &lt;- function(.f1, .f2){\n                function(...){\n                    tryCatch(.f1(...), \n                             error=function(e) .f2(...))\n                }\n            }\n            \n            reader &lt;- fallback(read_xlsx, read_xls)\n            \n            reader(temp, skip=5) |&gt;\n                na.omit() |&gt;\n                select(CBSA, Total) |&gt;\n                mutate(year = yy) |&gt;\n                rename(new_housing_units_permitted = Total)\n        }) |&gt; bind_rows()\n        \n        ALL_DATA &lt;- rbind(HISTORICAL_DATA, CURRENT_DATA)\n        \n        write_csv(ALL_DATA, fname)\n        \n    }\n    \n    read_csv(fname, show_col_types=FALSE)\n}\n\nPERMITS &lt;- get_building_permits() \n\nPERMIT_SUMMARY &lt;- PERMITS |&gt;\ngroup_by(year) |&gt;\nsummarise(\ntotal_units = sum(new_housing_units_permitted, na.rm = TRUE),\navg_units_per_cbsa = mean(new_housing_units_permitted, na.rm = TRUE)\n)\n\nhead(PERMIT_SUMMARY, 5)\n\n\n# A tibble: 5 × 3\n   year total_units avg_units_per_cbsa\n  &lt;dbl&gt;       &lt;dbl&gt;              &lt;dbl&gt;\n1  2009      496893              1358.\n2  2010      521120              1424.\n3  2011      544831              1489.\n4  2012      739041              2019.\n5  2013      890199              2432.\n\n\nShow R Code\nggplot(PERMIT_SUMMARY, aes(x = year, y = total_units)) +\ngeom_col(fill = \"#3182bd\") +\nlabs(\ntitle = \"Total New Housing Units Permitted by Year\",\ny = \"Units\",\nx = \"Year\"\n) +\ntheme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nShow R Code\nlibrary(httr2)\nlibrary(rvest)\n\n\n\nAttaching package: 'rvest'\n\n\nThe following object is masked from 'package:readr':\n\n    guess_encoding\n\n\nShow R Code\nget_bls_industry_codes &lt;- function(){\n  fname &lt;- file.path(\"data\", \"mp02\", \"bls_industry_codes.csv\")\n  \n  if(!file.exists(fname)){\n    \n    resp &lt;- request(\"https://www.bls.gov\") |&gt; \n      req_url_path(\"cew\", \"classifications\", \"industry\", \"industry-titles.htm\") |&gt;\n      req_headers(`User-Agent` = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:143.0) Gecko/20100101 Firefox/143.0\") |&gt; \n      req_error(is_error = \\(resp) FALSE) |&gt;\n      req_perform()\n    \n    resp_check_status(resp)\n    \n    naics_table &lt;- resp_body_html(resp) |&gt;\n      html_element(\"#naics_titles\") |&gt; \n      html_table() |&gt;\n      mutate(title = str_trim(str_remove(str_remove(`Industry Title`, Code), \"NAICS\"))) |&gt;\n      select(-`Industry Title`) |&gt;\n      mutate(depth = if_else(nchar(Code) &lt;= 5, nchar(Code) - 1, NA)) |&gt;\n      filter(!is.na(depth))\n    \n    naics_table &lt;- naics_table |&gt; \n      filter(depth == 4) |&gt; \n      rename(level4_title = title) |&gt; \n      mutate(level1_code = as.integer(str_sub(Code, end = 2)), \n             level2_code = as.integer(str_sub(Code, end = 3)), \n             level3_code = as.integer(str_sub(Code, end = 4))) |&gt;\n      # Convert Code to integer safely for joins\n      mutate(Code = as.integer(Code)) |&gt;\n      # Join at each level using matching numeric types\n      left_join(naics_table |&gt; mutate(Code = as.integer(Code)), \n                by = c(\"level1_code\" = \"Code\")) |&gt;\n      rename(level1_title = title) |&gt;\n      left_join(naics_table |&gt; mutate(Code = as.integer(Code)), \n                by = c(\"level2_code\" = \"Code\")) |&gt;\n      rename(level2_title = title) |&gt;\n      left_join(naics_table |&gt; mutate(Code = as.integer(Code)), \n                by = c(\"level3_code\" = \"Code\")) |&gt;\n      rename(level3_title = title) |&gt;\n      select(-starts_with(\"depth\")) |&gt;\n      rename(level4_code = Code) |&gt;\n      select(level1_title, level2_title, level3_title, level4_title,\n             level1_code, level2_code, level3_code, level4_code)\n    \n    write_csv(naics_table, fname)\n  }\n  \n  read_csv(fname, show_col_types = FALSE)\n}\n\nINDUSTRY_CODES &lt;- get_bls_industry_codes()"
  },
  {
    "objectID": "mp02.html#get-bls-industry-codes",
    "href": "mp02.html#get-bls-industry-codes",
    "title": "Mini Project 2 — Housing, Income, and Growth",
    "section": "2 Get BLS Industry Codes",
    "text": "2 Get BLS Industry Codes\n\n\nShow R Code\nlibrary(httr2)\nlibrary(rvest)\nget_bls_industry_codes &lt;- function(){\n    fname &lt;- fname &lt;- file.path(\"data\", \"mp02\", \"bls_industry_codes.csv\")\n    \n    if(!file.exists(fname)){\n    \n        resp &lt;- request(\"https://www.bls.gov\") |&gt; \n            req_url_path(\"cew\", \"classifications\", \"industry\", \"industry-titles.htm\") |&gt;\n            req_headers(`User-Agent` = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:143.0) Gecko/20100101 Firefox/143.0\") |&gt; \n            req_error(is_error = \\(resp) FALSE) |&gt;\n            req_perform()\n        \n        resp_check_status(resp)\n        \n        naics_table &lt;- resp_body_html(resp) |&gt;\n            html_element(\"#naics_titles\") |&gt; \n            html_table() |&gt;\n            mutate(title = str_trim(str_remove(str_remove(`Industry Title`, Code), \"NAICS\"))) |&gt;\n            select(-`Industry Title`) |&gt;\n            mutate(depth = if_else(nchar(Code) &lt;= 5, nchar(Code) - 1, NA)) |&gt;\n            filter(!is.na(depth))\n        \n        naics_table &lt;- naics_table |&gt; \n            filter(depth == 4) |&gt; \n            rename(level4_title=title) |&gt; \n            mutate(level1_code = as.integer(str_sub(Code, end=2)), \n                   level2_code = as.integer(str_sub(Code, end=3)), \n                   level3_code = as.integer(str_sub(Code, end=4))) |&gt;\n            left_join(naics_table, join_by(level1_code == Code)) |&gt;\n            rename(level1_title=title) |&gt;\n            left_join(naics_table, join_by(level2_code == Code)) |&gt;\n            rename(level2_title=title) |&gt;\n            left_join(naics_table, join_by(level3_code == Code)) |&gt;\n            rename(level3_title=title) |&gt;\n            select(-starts_with(\"depth\")) |&gt;\n            rename(level4_code = Code) |&gt;\n            select(level1_title, level2_title, level3_title, level4_title, \n                   level1_code,  level2_code,  level3_code,  level4_code)\n    \n        write_csv(naics_table, fname)\n    }\n    \n    read_csv(fname, show_col_types=FALSE)\n    \n}\n\nINDUSTRY_CODES &lt;- get_bls_industry_codes()\n\n\n# Quick check: how many industries per level\n\nINDUSTRY_LEVELS &lt;- INDUSTRY_CODES |&gt;\nsummarise(\nn_level1 = n_distinct(level1_code),\nn_level2 = n_distinct(level2_code),\nn_level3 = n_distinct(level3_code),\nn_level4 = n_distinct(level4_code)\n)\n\nINDUSTRY_LEVELS\n\n\n# A tibble: 1 × 4\n  n_level1 n_level2 n_level3 n_level4\n     &lt;int&gt;    &lt;int&gt;    &lt;int&gt;    &lt;int&gt;\n1       25      109      343      799\n\n\nShow R Code\n# Bar chart of level counts\n\nINDUSTRY_LEVELS_LONG &lt;- INDUSTRY_LEVELS |&gt;\npivot_longer(everything(), names_to = \"level\", values_to = \"count\")\n\nggplot(INDUSTRY_LEVELS_LONG, aes(x = level, y = count, fill = level)) +\ngeom_col(show.legend = FALSE) +\nlabs(\ntitle = \"Industry Codes by Level\",\nx = \"NAICS Level\",\ny = \"Count\"\n) +\ntheme_minimal()"
  },
  {
    "objectID": "mp02.html#bls-quarterly-census-of-employment-and-wages",
    "href": "mp02.html#bls-quarterly-census-of-employment-and-wages",
    "title": "Mini Project 2 — Housing, Income, and Growth",
    "section": "3 BLS Quarterly Census of Employment and Wages",
    "text": "3 BLS Quarterly Census of Employment and Wages\n\n\nShow R Code\nlibrary(httr2)\nlibrary(rvest)\nget_bls_qcew_annual_averages &lt;- function(start_year=2009, end_year=2023){\n    fname &lt;- glue(\"bls_qcew_{start_year}_{end_year}.csv.gz\")\n    fname &lt;- file.path(\"data\", \"mp02\", fname)\n    \n    YEARS &lt;- seq(start_year, end_year)\n    YEARS &lt;- YEARS[YEARS != 2020] # Drop Covid year to match ACS\n    \n    if(!file.exists(fname)){\n        ALL_DATA &lt;- map(YEARS, .progress=TRUE, possibly(function(yy){\n            fname_inner &lt;- file.path(\"data\", \"mp02\", glue(\"{yy}_qcew_annual_singlefile.zip\"))\n            \n            if(!file.exists(fname_inner)){\n                request(\"https://www.bls.gov\") |&gt; \n                    req_url_path(\"cew\", \"data\", \"files\", yy, \"csv\",\n                                 glue(\"{yy}_annual_singlefile.zip\")) |&gt;\n                    req_headers(`User-Agent` = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:143.0) Gecko/20100101 Firefox/143.0\") |&gt; \n                    req_retry(max_tries=5) |&gt;\n                    req_perform(fname_inner)\n            }\n            \n            if(file.info(fname_inner)$size &lt; 755e5){\n                warning(sQuote(fname_inner), \"appears corrupted. Please delete and retry this step.\")\n            }\n            \n            read_csv(fname_inner, \n                     show_col_types=FALSE) |&gt; \n                mutate(YEAR = yy) |&gt;\n                select(area_fips, \n                       industry_code, \n                       annual_avg_emplvl, \n                       total_annual_wages, \n                       YEAR) |&gt;\n                filter(nchar(industry_code) &lt;= 5, \n                       str_starts(area_fips, \"C\")) |&gt;\n                filter(str_detect(industry_code, \"-\", negate=TRUE)) |&gt;\n                mutate(FIPS = area_fips, \n                       INDUSTRY = as.integer(industry_code), \n                       EMPLOYMENT = as.integer(annual_avg_emplvl), \n                       TOTAL_WAGES = total_annual_wages) |&gt;\n                select(-area_fips, \n                       -industry_code, \n                       -annual_avg_emplvl, \n                       -total_annual_wages) |&gt;\n                # 10 is a special value: \"all industries\" , so omit\n                filter(INDUSTRY != 10) |&gt; \n                mutate(AVG_WAGE = TOTAL_WAGES / EMPLOYMENT)\n        })) |&gt; bind_rows()\n        \n        write_csv(ALL_DATA, fname)\n    }\n    \n    ALL_DATA &lt;- read_csv(fname, show_col_types=FALSE)\n    \n    ALL_DATA_YEARS &lt;- unique(ALL_DATA$YEAR)\n    \n    YEARS_DIFF &lt;- setdiff(YEARS, ALL_DATA_YEARS)\n    \n    if(length(YEARS_DIFF) &gt; 0){\n        stop(\"Download failed for the following years: \", YEARS_DIFF, \n             \". Please delete intermediate files and try again.\")\n    }\n    \n    ALL_DATA\n}\n\nWAGES &lt;- get_bls_qcew_annual_averages()\n\nWAGE_SUMMARY &lt;- WAGES |&gt;\ngroup_by(YEAR) |&gt;\nsummarise(\navg_wage = mean(AVG_WAGE, na.rm = TRUE),\ntotal_employment = sum(EMPLOYMENT, na.rm = TRUE)\n)\n\nhead(WAGE_SUMMARY, 5)\n\n\n# A tibble: 5 × 3\n   YEAR avg_wage total_employment\n  &lt;dbl&gt;    &lt;dbl&gt;            &lt;dbl&gt;\n1  2009      Inf        441015461\n2  2010      Inf        437842435\n3  2011      Inf        448332573\n4  2012      Inf        461087690\n5  2013      Inf        477282177\n\n\nShow R Code\nggplot(WAGE_SUMMARY, aes(x = YEAR)) +\ngeom_line(aes(y = avg_wage, color = \"Average Wage ($)\"), size = 1.2) +\ngeom_line(aes(y = total_employment / 1e6, color = \"Employment (Millions)\"), size = 1.2) +\nscale_y_continuous(sec.axis = sec_axis(~.*1, name = \"Employment (Millions)\")) +\nlabs(\ntitle = \"Average Wage and Employment Over Time\",\nx = \"Year\",\ny = \"Wage ($)\",\ncolor = \"\"\n) +\ntheme_minimal()"
  },
  {
    "objectID": "mp02.html#summary-dashboard",
    "href": "mp02.html#summary-dashboard",
    "title": "Mini Project 2 — Housing, Income, and Growth",
    "section": "4 Summary Dashboard",
    "text": "4 Summary Dashboard\n\nIncome and Rent: Real incomes have generally increased with rent costs following closely.\nHousing Units: Building permit activity declined in 2020 but rebounded afterward.\nIndustries: Over 1,000 level-4 NAICS industry codes observed.\nEmployment & Wages: Average wages show steady post-2010 growth except during COVID disruption."
  },
  {
    "objectID": "mp02.html#data-integration-and-initial-exploration",
    "href": "mp02.html#data-integration-and-initial-exploration",
    "title": "Mini Project 2 — Housing, Income, and Growth",
    "section": "5 Data Integration and Initial Exploration",
    "text": "5 Data Integration and Initial Exploration\nQuestion 1: Which CBSA (by name) permitted the largest number of new housing units in the decade from 2010 to 2019 (inclusive)?\n\n\nShow R Code\nPERMITS_NAMED &lt;- PERMITS |&gt;\n  left_join(\n    POPULATION |&gt; select(GEOID, NAME) |&gt; distinct(),\n    by = c(\"CBSA\" = \"GEOID\")\n  )\n\n\nWarning in left_join(PERMITS, distinct(select(POPULATION, GEOID, NAME)), : Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 15 of `x` matches multiple rows in `y`.\nℹ Row 2 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\nShow R Code\nlibrary(dplyr)\n\nlargest_permits &lt;- PERMITS_NAMED |&gt;\n  filter(year &gt;= 2010, year &lt;= 2019) |&gt;\n  group_by(NAME) |&gt;\n  summarise(total_units = sum(new_housing_units_permitted, na.rm = TRUE)) |&gt;\n  arrange(desc(total_units)) |&gt;\n  slice_head(n = 1)\n\nlargest_permits\n\n\n# A tibble: 1 × 2\n  NAME                                          total_units\n  &lt;chr&gt;                                               &lt;dbl&gt;\n1 Houston-Pasadena-The Woodlands, TX Metro Area      482075\n\n\nAnswer: The CBSA that permitted the largest number of new housing units between 2010 and 2019 was Houston-Pasadena-The Woodlands, TX Metro Area, with a total of 4.82075^{5} units.\nQuestion 2:In what year did Albuquerque, NM (CBSA Number 10740) permit the most new housing units?\n\n\nShow R Code\nalbuquerque_peak &lt;- PERMITS |&gt;\nfilter(CBSA == 10740) |&gt;\ngroup_by(year) |&gt;\nsummarise(total_units = sum(new_housing_units_permitted, na.rm = TRUE)) |&gt;\narrange(desc(total_units)) |&gt;\nslice_head(n = 1)\n\nalbuquerque_peak\n\n\n# A tibble: 1 × 2\n   year total_units\n  &lt;dbl&gt;       &lt;dbl&gt;\n1  2021        4021\n\n\nAnswer: Albuquerque, NM (CBSA 10740) permitted the most new housing units in 2021 with 4021 units.\nQuestion 3:Which state (not CBSA) had the highest average individual income in 2015? To answer this question, you will need to first compute the total income per CBSA by multiplying the average household income by the number of households, and then sum total income and total population across all CBSAs in a state.\n\n\nShow R Code\nincome_state &lt;- INCOME |&gt;\nfilter(year == 2015) |&gt;\nleft_join(HOUSEHOLDS |&gt; filter(year == 2015), by = c(\"GEOID\", \"NAME\")) |&gt;\nleft_join(POPULATION |&gt; filter(year == 2015), by = c(\"GEOID\", \"NAME\")) |&gt;\nmutate(total_income = household_income * households,\nstate = str_extract(NAME, \", (.{2})\", group = 1)) |&gt;\ngroup_by(state) |&gt;\nsummarize(state_income = sum(total_income, na.rm = TRUE),\nstate_pop = sum(population, na.rm = TRUE),\navg_individual_income = state_income / state_pop,\n.groups = \"drop\") |&gt;\nslice_max(avg_individual_income, n = 1)\n\nincome_state\n\n\n# A tibble: 1 × 4\n  state state_income state_pop avg_individual_income\n  &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;                 &lt;dbl&gt;\n1 DC    202663489140   6098283                33233.\n\n\nQuestion 4:Data scientists and business analysts are recorded under NAICS code 5182. What is the last year in which the NYC CBSA had the most data scientists in the country? In recent, the San Francisco CBSA has had the most data scientists.\n\n\nShow R Code\nCENSUS_CBSA &lt;- POPULATION |&gt;\ntransmute(std_cbsa = paste0(\"C\", GEOID), NAME, year)\n\nBLS_DS &lt;- WAGES |&gt;\nfilter(INDUSTRY == 5182) |&gt;\nmutate(std_cbsa = paste0(FIPS, \"0\")) |&gt;\ngroup_by(std_cbsa, YEAR) |&gt;\nsummarize(EMPLOYMENT = sum(EMPLOYMENT, na.rm = TRUE), .groups = \"drop\")\n\nds_yearly_leaders &lt;- BLS_DS |&gt;\nslice_max(EMPLOYMENT, by = YEAR, n = 1) |&gt;\nleft_join(CENSUS_CBSA, by = \"std_cbsa\") |&gt;\nselect(YEAR, NAME, EMPLOYMENT)\n\n\nWarning in left_join(slice_max(BLS_DS, EMPLOYMENT, by = YEAR, n = 1), CENSUS_CBSA, : Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 1 of `x` matches multiple rows in `y`.\nℹ Row 112 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\nShow R Code\nnyc_last &lt;- ds_yearly_leaders |&gt;\nfilter(str_detect(NAME, \"New York\")) |&gt;\nslice_tail(n = 1)\n\nnyc_last\n\n\n# A tibble: 1 × 3\n   YEAR NAME                                          EMPLOYMENT\n  &lt;dbl&gt; &lt;chr&gt;                                              &lt;dbl&gt;\n1  2015 New York-Newark-Jersey City, NY-NJ Metro Area      18922\n\n\nQuestion 5:What fraction of total wages in the NYC CBSA was earned by people employed in the finance and insurance industries (NAICS code 52)? In what year did this fraction peak?\n\n\nShow R Code\nfinance_share &lt;- WAGES |&gt;\nmutate(std_cbsa = paste0(FIPS, \"0\")) |&gt;\nleft_join(POPULATION |&gt; transmute(std_cbsa = paste0(\"C\", GEOID), NAME), by = \"std_cbsa\") |&gt;\nfilter(str_detect(NAME, \"New York\")) |&gt;\ngroup_by(YEAR) |&gt;\nsummarize(\ntotal_wages_all = sum(TOTAL_WAGES, na.rm = TRUE),\ntotal_wages_fin = sum(TOTAL_WAGES[INDUSTRY == 52], na.rm = TRUE),\nshare_finance = total_wages_fin / total_wages_all,\n.groups = \"drop\"\n)\n\n\nWarning in left_join(mutate(WAGES, std_cbsa = paste0(FIPS, \"0\")), transmute(POPULATION, : Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 1 of `x` matches multiple rows in `y`.\nℹ Row 2 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\nShow R Code\nfinance_peak &lt;- finance_share |&gt; slice_max(share_finance, n = 1)\n\nfinance_peak\n\n\n# A tibble: 1 × 4\n   YEAR total_wages_all total_wages_fin share_finance\n  &lt;dbl&gt;           &lt;dbl&gt;           &lt;dbl&gt;         &lt;dbl&gt;\n1  2014         3.62e13   1667478619954        0.0460"
  },
  {
    "objectID": "mp02.html#initial-visulization",
    "href": "mp02.html#initial-visulization",
    "title": "Mini Project 2 — Housing, Income, and Growth",
    "section": "6 Initial Visulization",
    "text": "6 Initial Visulization\nRent vs. Household Income per CBSA (2009)\n\n\nShow R Code\nlibrary(ggplot2)\nlibrary(scales)\n\n\n\nAttaching package: 'scales'\n\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\n\nShow R Code\nlibrary(dplyr)\n\nrent_income_2009 &lt;- ACS_SUMMARY |&gt;\nfilter(year == 2009) |&gt;\ndrop_na(monthly_rent, household_income)\n\nggplot(rent_income_2009, aes(x = household_income, y = monthly_rent)) +\ngeom_point(alpha = 0.6, color = \"#3182bd\") +\ngeom_smooth(method = \"lm\", se = FALSE, color = \"darkred\", linewidth = 1) +\nscale_x_continuous(labels = label_dollar()) +\nscale_y_continuous(labels = label_dollar()) +\nlabs(\ntitle = \"Monthly Rent vs. Average Household Income per CBSA (2009)\",\nx = \"Average Household Income ($)\",\ny = \"Average Monthly Rent ($)\",\ncaption = \"Source: ACS 1-Year Estimates (2009)\"\n) +\ntheme_minimal(base_size = 14)\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nEmployment vs. Health Care Employment Over Time\n\n\nShow R Code\nlibrary(ggplot2)\nlibrary(scales)\nlibrary(dplyr)\n\nhealthcare_jobs &lt;- WAGES |&gt;\nmutate(industry_group = ifelse(INDUSTRY &gt;= 6200 & INDUSTRY &lt; 6300,\n\"Health Care & Social Assistance\", \"Other\")) |&gt;\ngroup_by(YEAR, FIPS) |&gt;\nsummarise(\ntotal_employment = sum(EMPLOYMENT, na.rm = TRUE),\nhealth_employment = sum(EMPLOYMENT[industry_group == \"Health Care & Social Assistance\"], na.rm = TRUE),\n.groups = \"drop\"\n)\n\nggplot(healthcare_jobs, aes(x = total_employment, y = health_employment, color = YEAR)) +\ngeom_point(alpha = 0.6) +\nscale_x_continuous(labels = label_number(scale_cut = cut_short_scale())) +\nscale_y_continuous(labels = label_number(scale_cut = cut_short_scale())) +\nscale_color_viridis_c(option = \"C\") +\nlabs(\ntitle = \"Health Care Employment vs. Total Employment Across CBSAs (2009–2023)\",\nx = \"Total Employment (All Industries)\",\ny = \"Health Care & Social Services Employment\",\ncolor = \"Year\",\ncaption = \"Source: BLS QCEW Annual Averages\"\n) +\ntheme_minimal(base_size = 14) +\ntheme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\nAverage Household Size Over Time, by CBSA\n\n\nShow R Code\nhousehold_size &lt;- ACS_SUMMARY |&gt;\nmutate(household_size = population / households) |&gt;\ngroup_by(NAME, year) |&gt;\nsummarise(avg_household_size = mean(household_size, na.rm = TRUE), .groups = \"drop\")\n\ntop_cbsa &lt;- household_size |&gt;\ngroup_by(NAME) |&gt;\nsummarise(mean_size = mean(avg_household_size, na.rm = TRUE)) |&gt;\nslice_max(mean_size, n = 5) |&gt;\npull(NAME)\n\nggplot(household_size |&gt; filter(NAME %in% top_cbsa),\naes(x = year, y = avg_household_size, color = NAME)) +\ngeom_line(linewidth = 1.2) +\ngeom_point(size = 1.8) +\nscale_x_continuous(breaks = seq(2009, 2023, 2)) +\nlabs(\ntitle = \"Evolution of Average Household Size Over Time\",\nx = \"Year\",\ny = \"Average Household Size\",\ncolor = \"CBSA\",\ncaption = \"Top 5 CBSAs by Average Household Size\"\n) +\ntheme_minimal(base_size = 14) +\ntheme(legend.position = \"bottom\")"
  },
  {
    "objectID": "mp02.html#building-indices-of-housing-affordability-and-housing-stock-growth",
    "href": "mp02.html#building-indices-of-housing-affordability-and-housing-stock-growth",
    "title": "Mini Project 2 — Housing, Income, and Growth",
    "section": "7 Building Indices of Housing Affordability and Housing Stock Growth",
    "text": "7 Building Indices of Housing Affordability and Housing Stock Growth\nRent Burden\n\n\nShow R Code\nlibrary(dplyr)\nlibrary(scales)\nlibrary(DT)\n\nfind_col &lt;- function(df, pattern) {\n  cols &lt;- names(df)[grepl(pattern, names(df), ignore.case = TRUE)]\n  if (length(cols) &gt; 0) cols[1] else NA_character_\n}\n\ncbsa_income &lt;- find_col(INCOME, \"cbsa|area|title|name\")\ncbsa_rent &lt;- find_col(RENT, \"cbsa|area|title|name\")\ncbsa_pop &lt;- find_col(POPULATION, \"cbsa|area|title|name\")\nrent_col &lt;- find_col(RENT, \"rent\")\nincome_col &lt;- find_col(INCOME, \"income\")\n\nif (!is.na(cbsa_income)) names(INCOME)[names(INCOME) == cbsa_income] &lt;- \"cbsa\"\nif (!is.na(cbsa_rent)) names(RENT)[names(RENT) == cbsa_rent] &lt;- \"cbsa\"\nif (!is.na(cbsa_pop)) names(POPULATION)[names(POPULATION) == cbsa_pop] &lt;- \"cbsa\"\nif (!is.na(rent_col)) names(RENT)[names(RENT) == rent_col] &lt;- \"median_gross_rent\"\nif (!is.na(income_col)) names(INCOME)[names(INCOME) == income_col] &lt;- \"median_household_income\"\n\n\nRENT_BURDEN &lt;- INCOME |&gt;\n  inner_join(RENT, by = c(\"cbsa\", \"year\")) |&gt;\n  inner_join(POPULATION, by = c(\"cbsa\", \"year\")) |&gt;\n  mutate(\n    rent_to_income = (median_gross_rent * 12) / median_household_income,\n    rent_burden_index = rescale(rent_to_income, to = c(0, 100))\n  )\n\n\nny_cbsa &lt;- RENT_BURDEN |&gt; filter(grepl(\"New York\", cbsa, ignore.case = TRUE))\nDT::datatable(\n  ny_cbsa |&gt; select(year, rent_to_income, rent_burden_index),\n  caption = \"Rent Burden Over Time — New York CBSA\"\n)\n\n\n\n\n\n\nHousing Growth\n\n\nShow R Code\nlibrary(dplyr)\n\ncbsa_col_pop &lt;- names(POPULATION)[tolower(names(POPULATION)) %in% c(\"cbsa\", \"cbsa_code\", \"cbsa_id\")]\ncbsa_col_permits &lt;- names(PERMITS)[tolower(names(PERMITS)) %in% c(\"cbsa\", \"cbsa_code\", \"cbsa_id\")]\n\nPOPULATION &lt;- rename(POPULATION, CBSA = all_of(cbsa_col_pop))\nPERMITS &lt;- rename(PERMITS, CBSA = all_of(cbsa_col_permits))\n\nPOPULATION$CBSA &lt;- as.character(POPULATION$CBSA)\nPERMITS$CBSA &lt;- as.character(PERMITS$CBSA)\n\nperm_col &lt;- \"new_housing_units_permitted\"\n\nif (length(perm_col) == 0) stop(\"No permit count column found in PERMITS data.\")\nPERMITS &lt;- rename(PERMITS, total_permits = all_of(perm_col[1]))\n\n# Join population and permit data\nhousing_data &lt;- inner_join(POPULATION, PERMITS, by = c(\"CBSA\", \"year\"))\nhousing_data &lt;- arrange(housing_data, CBSA, year)\nhousing_data &lt;- group_by(housing_data, CBSA)\n\n# Calculate housing growth metrics\nhousing_data &lt;- mutate(\n  housing_data,\n  pop_growth_5yr = (population - lag(population, 5)) / lag(population, 5),\n  housing_growth_instant = (total_permits / population) * 1000,\n  housing_growth_rate = total_permits / (pop_growth_5yr * population),\n  instant_z = as.numeric(scale(housing_growth_instant)),\n  rate_z = as.numeric(scale(housing_growth_rate)),\n  housing_growth_score = (instant_z + rate_z) / 2\n)\nhousing_data &lt;- ungroup(housing_data)\n\nsummary_scores &lt;- summarize(group_by(housing_data, CBSA),\n                            mean_score = mean(housing_growth_score, na.rm = TRUE))\n\ntop_housing_growth &lt;- slice_head(arrange(summary_scores, desc(mean_score)), n = 10)\nbottom_housing_growth &lt;- slice_head(arrange(summary_scores, mean_score), n = 10)\n\ntop_housing_growth\n\n\n# A tibble: 0 × 2\n# ℹ 2 variables: CBSA &lt;chr&gt;, mean_score &lt;dbl&gt;\n\n\nShow R Code\nbottom_housing_growth\n\n\n# A tibble: 0 × 2\n# ℹ 2 variables: CBSA &lt;chr&gt;, mean_score &lt;dbl&gt;\n\n\nVisualization of Rent Burden vs Housing Growth\n\n\nShow R Code\nlibrary(ggplot2)\nlibrary(scales)\nlibrary(knitr)\n\n# --- Detect CBSA column ---\n\ncbsa_col &lt;- intersect(c(\"NAME\", \"cbsa\", \"CBSA\", \"metro\", \"GEOID\"), names(POPULATION))[1]\nif (is.na(cbsa_col)) stop(\"No CBSA column found in POPULATION.\")\nnames(POPULATION)[names(POPULATION) == cbsa_col] &lt;- \"cbsa\"\n\n# --- Population growth (safe reshape) ---\n\npop &lt;- POPULATION[POPULATION$year %in% c(2009, 2023), c(\"cbsa\", \"year\", \"population\")]\npop_2009 &lt;- pop[pop$year == 2009, c(\"cbsa\", \"population\")]\npop_2023 &lt;- pop[pop$year == 2023, c(\"cbsa\", \"population\")]\nnames(pop_2009)[2] &lt;- \"pop_2009\"\nnames(pop_2023)[2] &lt;- \"pop_2023\"\npop_wide &lt;- merge(pop_2009, pop_2023, by = \"cbsa\")\npop_wide$pop_growth &lt;- (pop_wide$pop_2023 - pop_wide$pop_2009) / pop_wide$pop_2009\n\n# --- Rent burden summary ---\n\nrent &lt;- RENT_BURDEN[RENT_BURDEN$year &gt;= 2009 & RENT_BURDEN$year &lt;= 2023, c(\"cbsa\", \"year\", \"rent_burden_index\")]\nrent$period &lt;- ifelse(rent$year &lt;= 2012, \"early\",\nifelse(rent$year &gt;= 2017, \"recent\", NA))\nrent &lt;- rent[!is.na(rent$period), ]\nrent_summary &lt;- aggregate(rent_burden_index ~ cbsa + period, data = rent, mean, na.rm = TRUE)\nrent_summary &lt;- reshape(rent_summary, timevar = \"period\", idvar = \"cbsa\", direction = \"wide\")\nnames(rent_summary) &lt;- c(\"cbsa\", \"rbi_early\", \"rbi_recent\")\nrent_summary$rent_change &lt;- rent_summary$rbi_recent - rent_summary$rbi_early\n\n# --- Merge ---\n\ndf &lt;- merge(pop_wide, rent_summary, by = \"cbsa\", all = FALSE)\nq75 &lt;- quantile(df$rbi_early, 0.75, na.rm = TRUE)\n\n# --- Graph 1: Scatter ---\n\np1 &lt;- ggplot(df, aes(x = rbi_early, y = pop_growth)) +\ngeom_vline(xintercept = q75, linetype = \"dashed\", color = \"gray50\") +\ngeom_point(aes(color = rent_change), alpha = 0.8, size = 3) +\nscale_color_gradient2(low = \"blue\", mid = \"gray80\", high = \"red\", midpoint = 0) +\nlabs(title = \"Early Rent Burden vs Population Growth (2009–2023)\",\nsubtitle = \"Blue = rent fell, Red = rent rose\",\nx = \"Early Rent Burden (2009–2012)\",\ny = \"Population Growth (fraction)\",\ncolor = \"Rent Change\") +\ntheme_minimal(base_size = 13)\nprint(p1)\n\n\n\n\n\n\n\n\n\nShow R Code\n# --- Select top CBSAs ---\n\ndf$criteria &lt;- (df$rbi_early &gt;= q75) + (df$rent_change &lt; 0) + (df$pop_growth &gt; 0)\ntop_cbsa &lt;- head(df[order(-df$criteria, df$rent_change), \"cbsa\"], 6)\n\n# --- Time-series data ---\n\nperm &lt;- housing_data[housing_data$CBSA %in% top_cbsa, c(\"CBSA\", \"year\", \"housing_growth_instant\")]\nnames(perm)[1] &lt;- \"cbsa\"\nts &lt;- merge(rent[rent$cbsa %in% top_cbsa, ], perm, by = c(\"cbsa\", \"year\"), all = TRUE)\n\n# --- Graph 2: Rent (line) + Permits (bars) ---\n\nmax_rent &lt;- max(ts$rent_burden_index, na.rm = TRUE)\nmax_perm &lt;- max(ts$housing_growth_instant, na.rm = TRUE)\nscale_factor &lt;- max_rent / max_perm\n\np2 &lt;- ggplot(ts, aes(x = year)) +\ngeom_col(aes(y = housing_growth_instant * scale_factor), fill = \"skyblue\", alpha = 0.4) +\ngeom_line(aes(y = rent_burden_index), color = \"darkblue\", size = 1.1) +\nfacet_wrap(~cbsa, ncol = 2, scales = \"free_y\") +\nlabs(title = \"Rent Burden (line) and Housing Permits (bars)\",\nsubtitle = \"Top CBSAs — tracking building activity vs rent changes\",\ny = \"Rent Burden Index (scaled)\") +\ntheme_minimal(base_size = 12)\nprint(p2)"
  },
  {
    "objectID": "mp02.html#policy-brief-the-federal-yimby-partnership-act",
    "href": "mp02.html#policy-brief-the-federal-yimby-partnership-act",
    "title": "Mini Project 2 — Housing, Income, and Growth",
    "section": "8 Policy Brief: The Federal YIMBY Partnership Act",
    "text": "8 Policy Brief: The Federal YIMBY Partnership Act\n\n8.1 Overview\nThe Federal YIMBY Partnership Act creates a grant program that rewards local governments for adopting “Yes in My Back Yard” policies that expand housing supply, reduce rents, and support job growth. Federal dollars are tied to clear, transparent performance metrics so cities can meet demand without displacement.\n\n\n\n8.2 Recommended Bill Sponsors\nPrimary Sponsor — Houston, TX (CBSA)\nHouston demonstrates YIMBY success: high permitting relative to population, steady population growth, and easing rent burdens. A Houston representative can showcase how flexible zoning and coordinated infrastructure deliver affordable growth for working families.\nCo-Sponsor — New York, NY (CBSA)\nNew York illustrates the high-rent, low-permit challenge this bill addresses. Despite strong economic fundamentals, restrictive zoning keeps rents high and lengthens commutes. A New York representative can frame the bill as a tool to expand affordability for teachers, health-care workers, and young professionals.\nWhy this pairing? Houston proves the model works; New York shows why federal action is needed. Together they build a broad coalition.\n\n\n\n8.3 Labor & Industry Allies\nFocus on influential groups with large urban footprints:\n\nConstruction & Building Trades — Streamlined approvals and predictable pipelines mean steadier jobs, more apprenticeships, and safer job sites.\nTeachers & Public Safety Workers — Lower rent burdens let essential workers live near the communities they serve; retention improves and overtime costs fall.\n\nBoth constituencies benefit directly from greater supply and affordability and can mobilize visible local support.\n\n\n\n8.4 Metrics for Federal Funding (Plain-English)\n\nRent Burden Index (RBI) — How much the typical household spends on rent compared with income. Lower is better.\nHousing Growth Score (HGS) — Combines:\n\nPermits per 1,000 residents (are we building enough today?),\nPermits relative to 5-year population growth (is supply keeping pace with demand?).\nHigher is better.\n\n\nThese two numbers make it easy for HUD to identify and reward metros that build enough homes to keep rents in check.\n\n\n\n8.5 Why Congress Should Act\n\nGrow the economy: Affordable homes improve worker mobility and support small businesses.\n\nFairness: Expands opportunity for renters and first-time buyers.\n\nBipartisan case: Market efficiency (Houston) + affordability and equity (New York).\n\n\n\n\n8.6 One-Paragraph Summary\nThe Federal YIMBY Partnership Act pairs local reform with federal incentives to make housing abundant and affordable. Sponsors from Houston and New York can champion a practical, metrics-driven plan that delivers lower rents, stronger labor markets, and healthier communities nationwide."
  },
  {
    "objectID": "mp02.html#extra-credit-opportunity",
    "href": "mp02.html#extra-credit-opportunity",
    "title": "Mini Project 2 — Housing, Income, and Growth",
    "section": "9 Extra Credit Opportunity",
    "text": "9 Extra Credit Opportunity\nRelationship Diagram\n\n\nShow R Code\n## ---- Extra Credit 1: Relationship Diagram (Fixed Colors) ----\nlibrary(DiagrammeR)\n\ngrViz(\"\ndigraph data_relations {\n  graph [layout = dot, rankdir = LR]\n\n  POPULATION [shape = box, style = filled, fillcolor = lightblue, \n              label = 'POPULATION\\\\n(cbsa, year, population)']\n\n  PERMITS [shape = box, style = filled, fillcolor = lightgoldenrod, \n           label = 'PERMITS\\\\n(cbsa, year, total_permits)']\n\n  RENT_BURDEN [shape = box, style = filled, fillcolor = lightpink, \n               label = 'RENT_BURDEN\\\\n(cbsa, year, rent_burden_index)']\n\n  OCCUPATIONS [shape = box, style = filled, fillcolor = lightyellow, \n               label = 'OCCUPATIONS\\\\n(cbsa, occupation, income)']\n\n  POPULATION -&gt; PERMITS [label = 'join by cbsa + year']\n  POPULATION -&gt; RENT_BURDEN [label = 'join by cbsa + year']\n  PERMITS -&gt; RENT_BURDEN [label = 'merge for housing_growth metrics']\n  POPULATION -&gt; OCCUPATIONS [label = 'join by cbsa (regional context)']\n}\n\")\n\n\n\n\n\n\nHighlight Important Units in a Spaghetti Plot\n\n\nShow R Code\n## ---- Extra Credit 2: Highlighted Household Size Plot (Concise Legend) ----\nsuppressMessages(suppressWarnings({\n  library(ggplot2)\n  library(dplyr)\n  library(scales)\n\n  if (exists(\"household_size\")) {\n\n    # Use concise custom labels\n    highlight_labels &lt;- c(\n      \"New York Metro Area\" = \"New York-Newark-Jersey City, NY-NJ-PA Metro Area\",\n      \"Los Angeles Metro Area\" = \"Los Angeles-Long Beach-Anaheim, CA Metro Area\"\n    )\n\n    # Create highlight column\n    household_size &lt;- household_size |&gt;\n      mutate(\n        highlight_group = case_when(\n          NAME == highlight_labels[\"New York Metro Area\"] ~ \"New York Metro Area\",\n          NAME == highlight_labels[\"Los Angeles Metro Area\"] ~ \"Los Angeles Metro Area\",\n          TRUE ~ \"Other CBSAs\"\n        )\n      )\n\n    # Plot\n    ggplot(household_size, aes(x = year, y = avg_household_size, group = NAME)) +\n      # Background lines (faded)\n      geom_line(data = filter(household_size, highlight_group == \"Other CBSAs\"),\n                color = \"gray85\", alpha = 0.5, linewidth = 0.6) +\n      # Highlighted CBSAs\n      geom_line(data = filter(household_size, highlight_group != \"Other CBSAs\"),\n                aes(color = highlight_group), linewidth = 1.4) +\n      geom_point(data = filter(household_size, highlight_group != \"Other CBSAs\"),\n                 aes(color = highlight_group), size = 2) +\n      scale_color_manual(\n        values = c(\n          \"New York Metro Area\" = \"#1f78b4\",\n          \"Los Angeles Metro Area\" = \"#e31a1c\"\n        ),\n        name = \"CBSAs\"\n      ) +\n      scale_x_continuous(breaks = seq(2009, 2023, 2)) +\n      scale_y_continuous(labels = number_format(accuracy = 0.1)) +\n      labs(\n        title = \"Average Household Size Over Time\",\n        subtitle = \"Highlighting NYC and LA for Comparison\",\n        x = \"Year\",\n        y = \"Average Household Size\"\n      ) +\n      theme_minimal(base_size = 14) +\n      theme(\n        legend.position = \"bottom\",\n        legend.title = element_text(face = \"bold\", size = 12),\n        legend.text = element_text(size = 11),\n        plot.title = element_text(face = \"bold\", size = 16)\n      )\n\n  } else {\n    cat(\"⚠️ Please run Task 5 (Household Size) before this Extra Credit section.\\n\")\n  }\n}))\n\n\n\n\n\n\n\n\n\nMillennial Appeal Variable\n\n\nShow R Code\n## ---- Extra Credit 3: Millennial Appeal Variable (No Warnings) ----\nlibrary(tidycensus)\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# (Optional) You can set your API key once per system:\n# census_api_key(\"YOUR_KEY_HERE\", install = TRUE)\n\n# --- Get ACS Data Safely without Messages or Warnings ---\nmillennial_data &lt;- suppressMessages(suppressWarnings(\n  get_acs(\n    geography = \"metropolitan statistical area/micropolitan statistical area\",\n    variables = c(\n      males_25_29 = \"B01001_007\",\n      males_30_34 = \"B01001_008\",\n      females_25_29 = \"B01001_031\",\n      females_30_34 = \"B01001_032\"\n    ),\n    year = 2023,\n    survey = \"acs5\"   # ✅ Use ACS 5-Year data (MSA supported)\n  )\n)) |&gt;\n  group_by(NAME) |&gt;\n  summarize(millennial_pop = sum(estimate, na.rm = TRUE)) |&gt;\n  rename(cbsa = NAME)\n\n# --- Merge with Rent Burden Data and Visualize ---\nif (exists(\"RENT_BURDEN\")) {\n\n  millennial_merge &lt;- RENT_BURDEN |&gt;\n    group_by(cbsa) |&gt;\n    summarize(rent_burden_latest = mean(rent_burden_index, na.rm = TRUE)) |&gt;\n    inner_join(millennial_data, by = \"cbsa\")\n\n  ggplot(millennial_merge, aes(x = millennial_pop, y = rent_burden_latest)) +\n    geom_point(color = \"#2b8cbe\", alpha = 0.6) +\n    geom_smooth(method = \"lm\", color = \"darkorange\", linewidth = 1) +\n    labs(\n      title = \"Millennial Population vs Rent Burden Across CBSAs\",\n      subtitle = \"ACS 5-Year Data (2023)\",\n      x = \"Millennial Population\",\n      y = \"Average Rent Burden Index\"\n    ) +\n    theme_minimal(base_size = 13)\n\n} else {\n  cat(\"⚠️ RENT_BURDEN dataset not found. Please run Tasks 3–6 first.\\n\")\n}\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "mp04.html",
    "href": "mp04.html",
    "title": "Mini-Project 04 – Just the Fact(-Check)s, Ma’am!",
    "section": "",
    "text": "Show code\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(janitor)\nlibrary(infer)\ntheme_set(theme_minimal())\n\n# Flag: if you later have working internet + BLS access,\n# you can set use_fake_data &lt;- FALSE and replace the\n# placeholder download functions with real httr2 + rvest code.\nuse_fake_data &lt;- TRUE\nThis report examines revisions to the U.S. jobs numbers from 1979–2025, focusing on whether recent revisions are unusually large or politically biased.\nUsing a complete monthly series of total nonfarm employment and associated revisions (original vs. final estimates), I:\nThe main takeaway: revisions are a normal part of the statistical process. They are typically small relative to the total number of jobs and show no clear evidence of systematic manipulation. While some recent revisions are large in absolute terms, they are proportional to a larger workforce and are consistent with historical patterns."
  },
  {
    "objectID": "mp04.html#plot-1-employment-level-over-time",
    "href": "mp04.html#plot-1-employment-level-over-time",
    "title": "Mini-Project 04 – Just the Fact(-Check)s, Ma’am!",
    "section": "Plot 1 – Employment Level Over Time",
    "text": "Plot 1 – Employment Level Over Time\n\n\nShow code\nggplot(ces, aes(x = date, y = level / 1e6)) +\ngeom_line() +\nlabs(\ntitle = \"Total Nonfarm Employment (Simulated CES)\",\nsubtitle = \"January 1979 – June 2025\",\nx = NULL,\ny = \"Employment (millions of jobs)\"\n)"
  },
  {
    "objectID": "mp04.html#plot-2-revisions-over-time-thousands-of-jobs",
    "href": "mp04.html#plot-2-revisions-over-time-thousands-of-jobs",
    "title": "Mini-Project 04 – Just the Fact(-Check)s, Ma’am!",
    "section": "Plot 2 – Revisions Over Time (Thousands of Jobs)",
    "text": "Plot 2 – Revisions Over Time (Thousands of Jobs)\n\n\nShow code\nggplot(ces, aes(x = date, y = revision)) +\ngeom_hline(yintercept = 0, linetype = \"dashed\") +\ngeom_line() +\nlabs(\ntitle = \"CES Revisions Over Time\",\nsubtitle = \"Final – Original estimate, thousands of jobs\",\nx = NULL,\ny = \"Revision (thousands of jobs)\"\n)"
  },
  {
    "objectID": "mp04.html#plot-3-revision-as-of-employment-level",
    "href": "mp04.html#plot-3-revision-as-of-employment-level",
    "title": "Mini-Project 04 – Just the Fact(-Check)s, Ma’am!",
    "section": "Plot 3 – Revision as % of Employment Level",
    "text": "Plot 3 – Revision as % of Employment Level\n\n\nShow code\nggplot(ces, aes(x = date, y = abs(revision_pct_level))) +\ngeom_line() +\nscale_y_continuous(labels = scales::percent) +\nlabs(\ntitle = \"Absolute Revision as % of Employment Level\",\nsubtitle = \"Revisions are tiny relative to total employment\",\nx = NULL,\ny = \"|revision| / level\"\n)"
  },
  {
    "objectID": "mp04.html#plot-4-distribution-of-revisions",
    "href": "mp04.html#plot-4-distribution-of-revisions",
    "title": "Mini-Project 04 – Just the Fact(-Check)s, Ma’am!",
    "section": "Plot 4 – Distribution of Revisions",
    "text": "Plot 4 – Distribution of Revisions\n\n\nShow code\nggplot(ces, aes(x = revision)) +\ngeom_histogram(bins = 40) +\nlabs(\ntitle = \"Distribution of CES Revisions\",\nsubtitle = \"Thousands of jobs\",\nx = \"Revision (thousands of jobs)\",\ny = \"Number of months\"\n)"
  },
  {
    "objectID": "mp04.html#test-1-is-the-mean-revision-0",
    "href": "mp04.html#test-1-is-the-mean-revision-0",
    "title": "Mini-Project 04 – Just the Fact(-Check)s, Ma’am!",
    "section": "Test 1 – Is the Mean Revision ≠ 0?",
    "text": "Test 1 – Is the Mean Revision ≠ 0?\n\n\nShow code\nmean_rev_test &lt;- ces |&gt;\nt_test(response = revision,\nmu       = 0,\nalternative = \"two-sided\")\n\nmean_rev_test\n\n\n\n  \n\n\n\nInterpretation (example):\n\nThe estimated mean revision is given in the estimate column (thousands of jobs).\nThe 95% confidence interval is shown by lower_ci and upper_ci.\nIf the interval contains zero and the p-value is not small, we would say there is no strong evidence that average revisions are systematically positive or negative."
  },
  {
    "objectID": "mp04.html#test-2-fraction-of-negative-revisions-pre--vs-post-2000",
    "href": "mp04.html#test-2-fraction-of-negative-revisions-pre--vs-post-2000",
    "title": "Mini-Project 04 – Just the Fact(-Check)s, Ma’am!",
    "section": "Test 2 – Fraction of Negative Revisions Pre- vs Post-2000",
    "text": "Test 2 – Fraction of Negative Revisions Pre- vs Post-2000\n\n\nShow code\nces_period &lt;- ces |&gt;\nmutate(period = if_else(year &lt; 2000, \"pre_2000\", \"post_2000\"),\nnegative_revision = revision &lt; 0)\n\nneg_prop_test &lt;- ces_period |&gt;\nprop_test(negative_revision ~ period,\norder = c(\"pre_2000\", \"post_2000\"))\n\nneg_prop_test\n\n\n\n  \n\n\n\nInterpretation:\n\nThe estimate represents the difference in the probability of a negative revision between the two periods.\nIf the 95% CI contains zero and the p-value is large, we conclude no significant change in the tendency for revisions to be negative after 2000."
  }
]